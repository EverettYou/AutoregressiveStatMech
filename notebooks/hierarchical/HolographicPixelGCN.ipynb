{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holographic Pixel Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"model.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative models have been applied to solve Statistical Mechanics problems by learning to model the Boltzmann distribution of microscopic configurations given the energy functional. This project aims to explore the combination of both **flow-based** and **autoregressive** models together with ideas from **renormalization group** and **holography** to tackle **critical** (scale-free) spin systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Goals\n",
    "\n",
    "* Develop **hierachical flow-based and autoregressive models**, combining them in the hyperbolic space. (For hierachical flow see [NeuralRG](https://arxiv.org/pdf/1802.02840.pdf) and related works)\n",
    "  * Hierachical flow learns the holographic mapping (i.e. wavelet transformation) that brings spin configurations to their wavelet encodings (like Haar wavelet encodings) in the holographic bulk.\n",
    "  * Autoregressive model learns the base distribution of wavelet encodings in the holographic bulk instead of the spin configurations on the holographic boundary.\n",
    "\n",
    "* Generalize [descrete flow](https://arxiv.org/pdf/1905.10347.pdf) and [integer flow](https://arxiv.org/pdf/1905.07376.pdf) to generic **non-Abelian descrete groups** (previously proposed XOR and Mod-K transforms are $\\mathbb{Z}_2$ and $\\mathbb{Z}_K$ groups). Some future ideas [*Not implemented yet, the current project will use a fixed transformation (e.g. Haar wavelet)*]:\n",
    "  * Foward computation allow two group elements to perform a controlled transform, such as $(g_1,g_2)\\to(g_1,g_1 g_2)$ (can be left- or right-multiplication, inversion, conjugation ...). Non-Abelian group may provide sufficient scrambling. Abelian group can be embedded in non-abelian groups.\n",
    "  * Fuzzy group: focus on distribution of group elements which is contineous and can flow. Similar to the idea of Gumbel-softmax.\n",
    "  \n",
    "* Develop more flexible autoregressive model based on message passing on **directed causal graphs** in the holographic space using graph convolutional network (GCN) techniques. This will allow us to apply autoregressive model in the holographic bulk, where the causal relations depends on the flow-based model and can be quite involved. GCN provides us the flexibility to dynamically determine the neural network connectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scientific Goals\n",
    "\n",
    "* **Analyze the RG Flow (Down Sampling)**: autoregressive model is good at marginalize causal dependants, which correspond to the UV degree of freedom. This can be used to analyze the RG flow after training. \n",
    "* **Analyze the Scaling Behavior (Up Sampling)** If we impose parameter sharing across RG scales, the model could learn a scale invariant transformatioin rule that can be genralize to larger systems. This will allow us to perform finite-size scaling analysis by up sampling.\n",
    "* **Probe Operator Scaling Dimension**: using the wormhole idea in the holographic space by resampling UV latent variables. This provide us a novel approach to obtain scaling dimension without a notion of spacetime.\n",
    "* **Speed up Monte Carlo(?)**: Need to measure the dynamic exponent to see.\n",
    "* **Application - $S_N$ Models**: $S_N$ spin model have $N!$ spin states (corresponding to $S_N$ group elements) on each site, which grows with $N$ quickly. Local update will be inefficient in this case, will hierachical autoregressive model be more efficient? These models will be important for us to understand **entanglement transitions** in random quantum circuits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model consists of the following parts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/model.png\" alt=\"model\" width=\"360\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A generative model $p(x)$ consist of\n",
    "  * A base model $p(z)$ realized as an **autoregressive model**, which uses graph convolutional network techniques to compute conditional distributions on a directed causal graph.\n",
    "  * A stack of transformations containing\n",
    "     * A **bijective encoding** (beetween one-hot and categorical)\n",
    "     * A **renormalization group (RG) transformation** realized as a flow model (but currently fixed to be Haar wavelet transformation in this project).\n",
    "* An **energy model** $E(x)$ must be provided as input to drive the training.\n",
    "* All these modules are based on information provided by the infrastructure layer which contains:\n",
    "  * A **group model** to provide basic functions of group operation and group function evaluation.\n",
    "  * A **lattice model** to provide indexing of nodes and to construct the causal graph in the holographic bulk.\n",
    "  \n",
    "Finally, the model is trained to minize the variational free energy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Lattice` represents a $d$-dimensional regular grid lattice of size $L$ (containing totally $L^d$ sites).\n",
    "\n",
    "**Parameters:**\n",
    "- `size` (int) - lattice size $L$\n",
    "- `dimension` (int) - lattice dimension $d$\n",
    "\n",
    "**Properties:**\n",
    "- `sites` (int) - number of lattice sites, equals to $L^d$.\n",
    "- `nodes` (list) - containing *latent* and *physical* nodes in the lattice system.\n",
    "  - **Latent nodes**: $L^d$  nodes in the holographic bulk, hosting latent variables.\n",
    "  - **Physical nodes**: $L^d$ nodes on the holographic boundary, hosting physical variables.\n",
    "  - Each node is represented by a `Node` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: create a 2D lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lattice(4x4 grid)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latt = Lattice(4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lattice object hosts a list of nodes. (altogether $2L^d$ nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latt.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The renormalization group transformation will be organized on a binary tree, which coarse grains along one dimension in each step. The coarse graining direction cycles through all dimensions repeatedly. The information flow forms a [H-tree](https://en.wikipedia.org/wiki/H_tree) fractal. \n",
    "- *Internal* (branch) nodes of the binary tree = *latent* nodes.\n",
    "- *External* (leaf) nodes of the binary tree = *physical* nodes. Each physical node also carries a physical site index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/htree.png\" alt=\"index_systems\" width=\"180\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Node` represents a single node in the lattice. \n",
    "\n",
    "**Properties:**\n",
    "- `type` (str) - node type\n",
    "  - `'lat'` - latent node,\n",
    "  - `'phy'` - physical node.\n",
    "- `ind` (int) - node index.\n",
    "- `center` (Tensor) - $(x,y)$ coordinate projected to the boundary coordinate system.\n",
    "- `generation` (int) - the generation of node.\n",
    "- `parent` (Node) - point to the parent node (except for node 0).\n",
    "- `children` (list of Nodes) - (*for latent node only*) a pair of children nodes [ch1, ch2].\n",
    "- `site` - (*for physical node only*) site index of the physical node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: node properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind type gen  children parent site\n",
      "  0  lat   0         1            \n",
      "  1  lat   0       2,3      0     \n",
      "  2  lat   1       4,6      1     \n",
      "  3  lat   1       5,7      1     \n",
      "  4  lat   2      8,12      2     \n",
      "  5  lat   2      9,13      3     \n",
      "  6  lat   2     10,14      2     \n",
      "  7  lat   2     11,15      3     \n",
      "  8  lat   3     16,24      4     \n",
      "  9  lat   3     17,25      5     \n",
      " 10  lat   3     18,26      6     \n",
      " 11  lat   3     19,27      7     \n",
      " 12  lat   3     20,28      4     \n",
      " 13  lat   3     21,29      5     \n",
      " 14  lat   3     22,30      6     \n",
      " 15  lat   3     23,31      7     \n",
      " 16  phy   4                8    0\n",
      " 17  phy   4                9    8\n",
      " 18  phy   4               10    2\n",
      " 19  phy   4               11   10\n",
      " 20  phy   4               12    4\n",
      " 21  phy   4               13   12\n",
      " 22  phy   4               14    6\n",
      " 23  phy   4               15   14\n",
      " 24  phy   4                8    1\n",
      " 25  phy   4                9    9\n",
      " 26  phy   4               10    3\n",
      " 27  phy   4               11   11\n",
      " 28  phy   4               12    5\n",
      " 29  phy   4               13   13\n",
      " 30  phy   4               14    7\n",
      " 31  phy   4               15   15\n"
     ]
    }
   ],
   "source": [
    "latt = Lattice(4, 2)\n",
    "print('ind type gen  children parent site')\n",
    "for node in latt.nodes:\n",
    "    print('{:3d} {:>4s} {:3d} {:>9s} {:>6s} {:>4s}'.format(\n",
    "        node.ind, node.type, node.generation, \n",
    "        ','.join(str(c.ind) for c in node.children if c is not None), \n",
    "        str(node.parent.ind) if node.parent is not None else '', str(node.site) if node.site is not None else ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Haar Wavelet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the lattice structure, we can define:\n",
    "- The **shadow** of a node = the collection of physical nodes achievable from the node. It can be constructed by combining the shadow of children nodes recurrently.\n",
    "$$S(i) =\\left\\{\\begin{array}{cc}\\bigcup_{j\\in \\text{ch}(i)} S(j) & \\text{ch}(i)\\neq \\{\\}, \\\\\n",
    "\\{i\\} & \\text{ch}(i)= \\{\\}, \\\\\\end{array}\\right.$$\n",
    "- The **action range** of a latent node = the shadow of the 2nd child of the node, i.e. $A(i) = S(\\text{ch}_2(i))$.\n",
    "\n",
    "Each latent node $i$ labels a **Haar wavelet**, whose wave form  = one-hot encoding of the action range $A(i)$ of the node $i$. \n",
    "Define\n",
    "- **Decoding matrix** $D$, such that $D_{ij}=\\delta(i\\in A(j))$. $D$ is a matrix of $0,1$. $D$ is also modular (i.e. $\\det D =1$).\n",
    "- **Encoding matrix** $E$, $E=D^{-1}$. Because $D$ is modular, $E$ is also modular. In fact, it is a matrix of $0,\\pm1$.\n",
    "\n",
    "With these matrices, the *Haar wavelet* **encoding** and **decoding** map can be defined as\n",
    "$$\\text{encode: }z_a=\\prod_i x_i^{E_{a i}},\\quad\\text{decode: } x_i=\\prod_a z_a^{D_{i a}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: action sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind    action_sites\n",
      "  0 -> [0, 1, 2, 3]\n",
      "  1 -> [2, 3]\n",
      "  2 -> [1]\n",
      "  3 -> [3]\n"
     ]
    }
   ],
   "source": [
    "latt = Lattice(2, 2)\n",
    "print('ind    action_sites')\n",
    "for node in latt.nodes:\n",
    "    if node.type is 'lat':\n",
    "        print('{:3d} -> {}'.format(node.ind, node.action_sites()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wavelet_maps()` method provides the encoding and decoding maps (i.e $E$ and $D$ matrices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  0,  0,  0],\n",
       "         [-1,  0,  1,  0],\n",
       "         [-1,  1,  0,  0],\n",
       "         [ 0,  0, -1,  1]]),\n",
       " tensor([[1, 0, 0, 0],\n",
       "         [1, 0, 1, 0],\n",
       "         [1, 1, 0, 0],\n",
       "         [1, 1, 0, 1]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latt.wavelet_maps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoregressive model uses conditional probabilities to model the joint probability. Each conditional probability entails the underlying causal influence that a random variable will receive from its conditional variables. The causal relations form a *directed graph*, called the **causal graph**. Since we have mapped the RG transform to a binary tree universally, we only need to analyze the causal relations on the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/causal_graph.png\" alt=\"causal_graph\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the lattice structure, we define:\n",
    "- The **center** coordinate $\\vec{r}_i$ of node $i$: projection of the node to the holographic boundary.\n",
    "- The **generation** $g_i$ of node $i$: the graph distance of the node on the binary tree from the tree root. The root node has generation $g_i=0$, its children are of generation $g_i=1$, and so on.\n",
    "- The **vicinity set** $V_\\rho(i)$ of a given node $i$ includes the nodes whose centers are within a scaled radius from the given node. (When calculating distance, the peroidic boundary condition of the physical space is assumed.)\n",
    "$$V_\\rho(i)=\\{j|\\Vert\\vec{r}_j-\\vec{r}_i\\Vert /L < \\rho 2^{-g_i/d}\\},$$\n",
    "  The dimensionless parameter $\\rho$ controls the (relative) radius of the vicinity set.\n",
    "- The **relevant nodes** $R_\\rho(i)$ is the union of ancestors of all nodes on $V_\\rho(i)$, \n",
    "$$R_\\rho(i) = \\bigcup_{j\\in V_\\rho(i)}\\text{anc}(j).$$\n",
    "  Physically, the relevant nodes are the nodes in the past light-cone of the vicinity set of a node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind relevant_nodes\n",
      "  1 []\n",
      "  2 [1]\n",
      "  3 [2, 1]\n",
      "  4 [2, 1, 3]\n",
      "  5 [2, 1, 3, 4]\n",
      "  6 [5, 2, 3, 4, 1]\n",
      "  7 [5, 2, 6, 3, 4, 1]\n",
      "  8 [5, 2, 6, 3, 4, 1]\n",
      "  9 [8, 7, 5, 2, 3, 4, 1]\n",
      " 10 [8, 7, 2, 6, 3, 4, 1]\n",
      " 11 [7, 5, 2, 9, 10, 6, 3, 1]\n",
      " 12 [8, 5, 2, 9, 6, 3, 4, 1]\n",
      " 13 [8, 7, 5, 2, 9, 3, 4, 12, 1]\n",
      " 14 [7, 2, 10, 6, 11, 3, 4, 12, 1]\n",
      " 15 [7, 5, 2, 10, 6, 11, 3, 13, 1, 14]\n"
     ]
    }
   ],
   "source": [
    "latt = Lattice(4, 2)\n",
    "print('ind relevant_nodes')\n",
    "for node in latt.nodes[1:]:\n",
    "    if node.type is 'lat':\n",
    "        print('{:3d} {}'.format(node.ind, [node.ind for node in latt.relevant_nodes(node, 1.5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **causal graph** is a graph of all latent nodes. For every pair of nodes $(j,i)$ with $j\\in R_\\rho(i)$, a *directed edge* $j\\to i$ is assigned from $j$ to $i$. Each edge $j\\to i$ can be classified by the relationship between $j$ and $i$. The relatioship between $j$ and $i$ is characterized by the pair of integers $(g_{j}-g_{(j,i)},g_{i}-g_{(j,i)})$, where $g_{(j,i)}=\\max_{k\\in \\text{anc}(j)\\cup\\text{anc}(i)}g_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`causal_graph(radius=1.)` method returns the causal graph as a Graph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: (0, 1), 2: (0, 2), 3: (0, 3), 4: (1, 1), 5: (1, 3), 6: (2, 3), 7: (3, 3)},\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 3, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 3, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 3, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 3, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 3, 2, 5, 1, 6, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 3, 5, 2, 6, 1, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 3, 2, 5, 0, 0, 1, 6, 0, 0, 4, 7, 0, 0, 0, 0],\n",
       "         [0, 3, 5, 2, 0, 0, 6, 1, 0, 0, 7, 4, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = latt.causal_graph()\n",
    "graph.type_dict, graph.adjacency_matrix().to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the radius will include more edges to the causal graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Graph(16x16, 51 edges of 7 types),\n",
       " Graph(16x16, 85 edges of 9 types),\n",
       " Graph(16x16, 101 edges of 9 types))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latt.causal_graph(1.), latt.causal_graph(1.5), latt.causal_graph(2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Graph` represents a directed graph and provides methods to extend nodes and generate weighed adjacent matrices in sparse form. The graph contains \n",
    "- $N_t$ number of target nodes, \n",
    "- $N_s$ number of source nodes,\n",
    "- $N_e$ number of edges from source nodes to target nodes.\n",
    "\n",
    "The edge set $\\{j_k\\xrightarrow{e_k}i_k|k=0:N_e\\}$ can be encoded by the indices $[[i_0,i_1,\\cdots],[j_0,j_1\\cdots]]$ and the edge types $[e_0,e_1,\\cdots]$.\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- `dims` (tuple) - $(N_t, N_s)$ record the numbers of target and source nodes.\n",
    "- `indices` (LongTensor) - $2\\times N_e$ dimensional tensor specifying the indices of the target nodes (in row-0) and the source nodes (in row-1).\n",
    "- `edge_types` (LongTensor) - $N_e$ dimensional tensor specifying the type of the corresponding edge.\n",
    "- `source_depths` (LongTensor, optional) - $N_s$ dimensional tensor specifying depth assignment of source nodes.\n",
    "\n",
    "**Properties:**\n",
    "\n",
    "- `edge_depths` (LongTensor) - $N_e$ dimensional tensor specifying depth assignment of edges, which follows the depth assignment of the source node of each edge.\n",
    "- `max_depth`(int) - maximal depth.\n",
    "- `max_edge_type` (int) - maximal edge type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: construct a graph and show the adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 2, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = Graph((4,4), torch.tensor([[2,3,3],[1,1,2]]), torch.tensor([1,1,2]))\n",
    "graph.adjacency_matrix().to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depths\n",
    "\n",
    "If `source_depths` is not given, it will be calculated. Note that source depth can only be calculated when $N_t=N_s$.\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "Let $A$ be the adjacency matrix. $u$ is an one-hot vector encoding the active vertices. Initially, $u$ is set to all one. $d$ is the depth vector, initially assigned to all zero.\n",
    "  - $u'= \\text{bool}(A u > 0)$ gives the target vertices under adjacency map,\n",
    "  - if $\\Vert u'\\Vert_1=\\Vert u\\Vert_1$ stop, otherwise $d=d+u'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.source_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from which the maximal depth is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`edge_depths` can be inferred from `source_depths` directly given `indices`. Edge depth = depth of the source node of the edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edge_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Self-Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`add_self_loops(start=0)` method prepends self loops to the graph. It returns a new Graph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 2, 1, 0],\n",
       "        [0, 2, 3, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sl = graph.add_self_loops()\n",
    "graph_sl.adjacency_matrix().to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starting node for the self loop to be added can be specified by the `start` parameter. This can be used to avoid adding self loops to the first node (as the first latent node corresponds to the global symmetry and is a special node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 2, 1, 0],\n",
       "        [0, 2, 3, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sl = graph.add_self_loops(start=1)\n",
    "graph_sl.adjacency_matrix().to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`expand(target_dim, source_dim)` method extends the graph by the specified target $d_t$ and source $d_s$ dimensions, such that $(N_t, N_s)\\to(N_t d_t, N_s d_s)$ and $N_e\\to N_e d_t d_s$. It will return a new Graph object. The extended edges are indexed by $(k,a,b)$ with $k=0:N_e$, $a=0:d_t$, $b=0:d_s$,\n",
    "$$\\begin{split}&(j,b)\\xrightarrow{(e,a,b)} (i,a)\\\\ \\Rightarrow & d_s j + b\\xrightarrow{((e-1)d_t + a)d_s + b +1} d_t i + a\\end{split}$$.\n",
    "\n",
    "The source depth assignments will simply be repeated. The edge depth assignment will be reconstructed according to the new indices and source depth assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2]),\n",
       " tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  2,  3,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  4,  5,  6,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  2,  3,  7,  8,  9,  0,  0,  0],\n",
       "         [ 0,  0,  0,  4,  5,  6, 10, 11, 12,  0,  0,  0]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_ext = graph.expand(2, 3)\n",
    "graph_ext.source_depths, graph_ext.adjacency_matrix().to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self loops can be added and then expand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2]),\n",
       " tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  2,  3,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  4,  5,  6,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  7,  8,  9,  1,  2,  3,  0,  0,  0],\n",
       "         [ 0,  0,  0, 10, 11, 12,  4,  5,  6,  0,  0,  0],\n",
       "         [ 0,  0,  0,  7,  8,  9, 13, 14, 15,  1,  2,  3],\n",
       "         [ 0,  0,  0, 10, 11, 12, 16, 17, 18,  4,  5,  6]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_ext = graph.add_self_loops(start=1).expand(2, 3)\n",
    "graph_ext.source_depths, graph_ext.adjacency_matrix().to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sparse_matrix(vector, depth=None)` scatters the vector elements to the adjacency matrix according to the edge type. The sparse matrix will be on the same device as the given vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5., 56., 27., 84., 67., 84., 73., 60., 39., 86., 47., 56., 50., 84.,\n",
       "        22., 30., 69., 95.], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = (torch.rand(graph_ext.max_edge_type)*100).round().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without specific depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  5., 56., 27.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 84., 67., 84.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 73., 60., 39.,  5., 56., 27.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 86., 47., 56., 84., 67., 84.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 73., 60., 39., 50., 84., 22.,  5., 56., 27.],\n",
       "        [ 0.,  0.,  0., 86., 47., 56., 30., 69., 95., 84., 67., 84.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_ext.sparse_matrix(vector).to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a specific depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  5., 56., 27.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 84., 67., 84.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 73., 60., 39.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 86., 47., 56.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 73., 60., 39.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 86., 47., 56.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_ext.sparse_matrix(vector, 0).to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Group` represents a discrete group $G$ specified by the multiplication table. Group elements will be labeled by integers (ranging from 0 to the order of the group). The element 0 is always treated as the identity element of the group. \n",
    "\n",
    "**Properties:**\n",
    "- `order` (int) - group order $|G|$ = number of group elements.\n",
    "- `mul_table` (Parameter) - group multiplication table, as a $|G|\\times|G|$ dimensional matrix.\n",
    "- `inv_table` (Parameter) - group inversion table, as a $|G|$ dimensional vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a $S_3$ group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group(order=6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = SymmetricGroup(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goup multiplcation and inversion tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 4, 5],\n",
       "         [1, 0, 4, 5, 2, 3],\n",
       "         [2, 3, 0, 1, 5, 4],\n",
       "         [3, 2, 5, 4, 0, 1],\n",
       "         [4, 5, 1, 0, 3, 2],\n",
       "         [5, 4, 3, 2, 1, 0]]),\n",
       " tensor([0, 1, 2, 4, 3, 5]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.mul_table, G.inv_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying two tensors element-wise following the group multiplication rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 2, 1],\n",
       "        [5, 5, 5]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[0, 1, 2], [3, 4, 5]]).to(device)\n",
    "b = torch.tensor([[5, 4, 3], [2, 1, 0]]).to(device)\n",
    "G.mul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product of a tensor along a given axis. Axis specified by `dim`. Keep dimension can be set by `keepdim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 4], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.prod(a, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4],\n",
       "        [5]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.prod(a, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group inversion of a tensor (element-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [4, 3, 5]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.inv(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inversion can be alternatively implemented by negate the group elements and translate the \"negative\" elements to the legitimate range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [4, 3, 5]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.mod(-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward(input, val_table)` method performs element-wise evaluation of the *group function* $f:G\\to \\mathbb{R}$ specified by a value table. The default value table for symmetric group corresponds to the cycle counting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 2., 2.],\n",
       "        [1., 1., 2.]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G(a, G.default_val_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000],\n",
       "        [-0.5000, -0.5000,  0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G(a, val_table=torch.tensor([1.,0.,0.,-0.5,-0.5,0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model` represents an energy model to describe the statistical mechanical system. It provides the function to evalutate the energy of a configuration.\n",
    "\n",
    "**Parameters:**\n",
    "- `lattice` (Lattice) - lattice on which the model is defined.\n",
    "- `group` (Group) - group of the on-site degree of freedom.\n",
    "\n",
    "**Properties:**\n",
    "- `energy` (EnergyTerms) - a list of energy terms. It provide a forward method to evalute the energy of a given configuration, provided the information of lattice and group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a 2D Ising model on a square lattice\n",
    "$$H= -J \\sum_{i}(\\sigma_i\\sigma_{i+\\hat{x}} + \\sigma_i\\sigma_{i+\\hat{y}}).$$\n",
    "The Hamiltonian can be typed in as (see the following subsection for explaination of the notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hamiltonian at this point is just an abstract notation. It must be combined with the specific `Lattice` and `Group` setup to form a concrete energy model. The energy model itself is a torch module (without any trainable parameters), which can be used to evaluate the energy of any spin configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lattice): Lattice(4x4 grid)\n",
       "  (group): Group(order=2)\n",
       "  (energy): EnergyTerms(\n",
       "    (0): TwoBody(G -> [-0.5, 0.5] across [1, 0])\n",
       "    (1): TwoBody(G -> [-0.5, 0.5] across [0, 1])\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(H(0.5), Lattice(4, 2), SymmetricGroup(2)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate some spin configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0],\n",
       "         [1, 1, 0, 0],\n",
       "         [1, 0, 0, 1],\n",
       "         [0, 0, 0, 1]],\n",
       "\n",
       "        [[1, 0, 1, 1],\n",
       "         [1, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [1, 1, 1, 1]]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(2, (2, 4, 4)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalutate the energy of these spin configuraitons by the energy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4., -4.], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hamiltonian Scripting System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to facilitate the formulation of Hamiltonian intuitively, we introduce a scripting system. Physical Hamiltonians are always sum of local energy terms. Each energy term is a subclass of `nn.Module` and each Hamiltonian is a subclass of `nn.ModuleList` (which contains the collection of energy terms). In this way, the evaluation of the total energy of the Hamiltonian can be distributed to each energy term in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce two kinds of energy terms\n",
    "* `OnSite`: on-site energy term $E_1(g_i)$,\n",
    "* `TwoBody`: two-body interaction term $E_2(g_i,g_j)$.\n",
    "\n",
    "More types of interaction terms can be introduced under this framework if necessary. These energy terms are group functions: $E_1:G\\to\\mathbb{R}$, $E_2:G\\times G\\to\\mathbb{R}$. These group functions can be specified by value tables, which enumerate the value that each group element maps to. For example, for the $\\mathbb{Z}_2=\\{0,1\\}$ group ($0$-identity, $1$-flip), if we want to specify\n",
    "$$E_1(0)=+1, E_1(1)=-1,$$\n",
    "the value talbe is $[+1,-1]$. Such a term can be created as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OnSite(G -> [1.0, -1.0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OnSite([1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume the two-body term always take the form of\n",
    "$$E_2(g_i,g_j)=E_2(g_i^{-1}g_j),$$\n",
    "such that we will only need to a single-variable group function, unsing the same value table representation. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoBody(G -> [1.0, -1.0] across [1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwoBody([1,0],[1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The the first argument of the two body term specify the relative direction from site-$i$ to site-$j$. If the value table is not specified, the default group function will be used:\n",
    "* For generic `Group`, the default group function is the delta function (like Potts model), which maps the identity element to 1 and the others to 0.\n",
    "* For `SymmetricGroup`, the default group function is the cycle counting function (count the number of permutation cycles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add, subtract, scalar multiply and negate the energy terms. Energy terms adding together will be represented as a collection of terms in a list (`nn.ModuleList`), which corresponds to a Hamiltonian. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnergyTerms(\n",
       "  (0): TwoBody(5.2 across [1, 0])\n",
       "  (1): TwoBody(5.2 across [0, 1])\n",
       "  (2): OnSite(-2.8)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2.8 * OnSite() + 5.2 * (TwoBody([1,0]) + TwoBody([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haar Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HaarTransformation` is a bijective map between the spin configuration and the Haar wavelet encoding. It is used to realize a fixed version of the *invertible RG transform* (or the *holographic mapping*). In the future, it could be replaced by a trainable *descrete flow* model.\n",
    "- `_call(z)`: Decoding Map (Generation Flow) takes the wavelet component $z$ to the spin configuration $x$ following \n",
    "$$x_i = \\prod_a z_a^{D_{i a}}.$$\n",
    "- `_inverse(x)`: Encoding Map (Renormalization Flow) takes the spin configuration $x$ to the wavelet component $z$ following \n",
    "$$z_a = \\prod_i x_i^{E_{a i}}.$$\n",
    "Note that $E$ contains $-1$ elements, which should be treated as group inversion.\n",
    "\n",
    "**Parameters:**\n",
    "- `lattice` (Lattice) - lattice on which the model is defined.\n",
    "- `group` (Group) - group of the on-site degree of freedom.\n",
    "\n",
    "**Properties**\n",
    "- `encoding_mat` (LongTensor) - the encoding matrix $E$.\n",
    "- `decoding_mat` (LongTensor) - the decoding matrix $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a $S_3$ group. Generate some wavelet (latent) configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 5, 4, 4, 0, 5, 4, 5, 5, 4, 2, 5, 4, 3, 0], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = SymmetricGroup(3).to(device)\n",
    "z = torch.randint(G.order, (16,)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the 16 wavelet components to the spin configuration on a 4 x 4 lattice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4, 4, 3],\n",
       "        [5, 0, 2, 1],\n",
       "        [2, 4, 5, 3],\n",
       "        [2, 5, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = HaarTransform(Lattice(4, 2), G)\n",
    "x = ht(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform back and verify that the encoder and decoder are inverse to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 5, 4, 4, 0, 5, 4, 5, 5, 4, 2, 5, 4, 3, 0], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.inv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bulk Effective Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Haar wavelet transform is a fixed transformation, the latent variables are bijectively related to the physical variable, so anything that we want to measure in the bulk (polarization, correlation ...) can in principle be measured in Monte Carlo, but transforming the data set. In fact, we even know the bulk energy function. For a 4x4 lattice, it looks like\n",
    "\n",
    "$$\\begin{split}\n",
    "E&= \\tau_4 + \\tau_5 + \\tau_6 +\\cdots +\\tau_{15}\\\\\n",
    "&+\\tau_1\\tau_4+\\tau_1\\tau_6+\\tau_2\\tau_8+\\tau_2\\tau_{10}+\\cdots\\\\\n",
    "&+\\tau_4\\tau_8\\tau_9+\\tau_5\\tau_{10}\\tau_{11}+\\cdots\\\\\n",
    "&+\\tau_2\\tau_4\\tau_5\\tau_9+\\cdots\\\\\n",
    "&+\\tau_1\\tau_2\\tau_3\\tau_5\\tau_{11}\\tau_{14}+\\cdots\n",
    "\\end{split}$$\n",
    "\n",
    "The longest multi-spin interaction is of the order $\\sim\\ln L$ where $L$ is the system size. Such term arises from the two-body interaction of physical spins across two big trees. Our model should be deep enough to resolve the nontrivial conditional distribution due to these multi-spin interactions in the latent space. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Categorical Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OneHotCategoricalTransform` is a **bijective embedding** that convert between the group elements and their one-hot embeddings. This serves as an interface between the RG transformation (which works with group elements for efficiency) and the autoregressive model (which works with one-hot embeddings for training performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 5, 0],\n",
       "        [1, 1, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_cat = torch.randint(6, (2, 3)).to(device)\n",
    "z_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.]]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oc = OneHotCategoricalTransform(6)\n",
    "z_emb = oc.inv(z_cat)\n",
    "z_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 5, 0],\n",
       "        [1, 1, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oc(z_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GraphConvLayer` provides a graph convolution layer, given the graph structure. It performs separate linear maps for different types of edges, and propagate message along the edge direction\n",
    "\n",
    "$$y_a=\\sum_{b\\to a}w_{e(b\\to a)}x_b+ b_{e(b\\to a)},$$\n",
    "\n",
    "where $e(b\\to a)$ denotes the type of the edge $b\\to a$ and the summation goes through all edges in the directed graph. $w$ and $b$ are trainable weights and biases that depend on the edge type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "- `graph` (Graph) - causal graph (the unexpanded base graph) specifying the directed edges and edge types.\n",
    "- `in_features` (int) - number of input features (source dimension)\n",
    "- `out_features` (int) - number of output features (target dimension)\n",
    "- `bias` (bool) - whether or not to include bias\n",
    "- `self-loop` (bool or int) -  if True/False: whether adding self-loops to the graph, if set to integer: add self-loops with the starting node index set by the integer.\n",
    "\n",
    "**Properties:**\n",
    "- `weight_graph` - extended graph for weight matrix.\n",
    "- `bias_graph` (optional) - extended graph for bias matrix (bias is realized as the bias matrix multiplying a all-one vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward(x, depth=None)` method implements the linear map using sparse matrix multiplication (`y = weight_matrix @ x + bias_matrix @ unit`). \n",
    "- The input data `x` must be reshaped to a matrix, with all features collected to the 0-dimension, and all batch samples collected to the 1-dimension. The layer will not transpose and untranspose the data. Data interface should be realized at higher level (in the parent class `GraphConvNet`).\n",
    "- If `depth` is None, input will be forwarded through all edges in the causal graph. If `depth` is specified, input will only be forwarded through edges of the specific depth (that initiates from the source vertices of the specific depth)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphConvLayer(\n",
       "  in_features=3, out_features=2, bias=True, self_loop=True\n",
       "  Graph(4x4, 7 edges of 3 types)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcl = GraphConvLayer(Lattice(2, 2).causal_graph(), 3, 2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some input of shape `[num_vertices * in_features, batch_size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9447e-01,  5.2489e-01,  7.3775e-01,  4.2769e-01, -3.1429e-01],\n",
       "        [ 2.5169e-01, -3.5346e-01,  5.9166e-01, -2.0530e-01, -4.5000e-01],\n",
       "        [-9.7972e-01,  5.5345e-01, -4.1122e-01, -8.0314e-01,  2.3169e+00],\n",
       "        [-2.0738e-02, -4.3500e-01, -6.1127e-01,  1.0509e-01, -6.3991e-01],\n",
       "        [ 5.9683e-01,  1.3351e+00,  1.8012e-01, -2.8274e-01, -6.0659e-01],\n",
       "        [ 1.1868e+00,  4.4157e-01,  1.2528e+00, -1.3956e+00,  2.0113e-01],\n",
       "        [-2.0581e+00, -9.1185e-01,  1.1170e+00,  1.6426e+00, -1.0980e-01],\n",
       "        [ 5.8024e-01, -5.5019e-04,  1.4261e+00,  6.4957e-01, -2.4456e-01],\n",
       "        [ 7.2026e-01,  1.3925e+00,  4.2983e-01, -1.3020e+00, -3.1377e-01],\n",
       "        [-5.9194e-01,  6.0635e-02,  6.2187e-01, -3.5552e-01, -1.2573e+00],\n",
       "        [-1.4416e-02,  6.1286e-01,  3.0148e-02,  1.6762e+00,  1.6216e-02],\n",
       "        [-4.3150e-02, -5.4225e-01, -6.2300e-01,  2.2091e-01,  1.5071e+00]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(gcl.source_dim,5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward the input all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6215,  0.3852,  0.7122,  0.4704,  0.2697],\n",
       "        [-0.1533, -0.4902, -0.3725, -0.1220, -0.8606],\n",
       "        [ 0.6359,  0.8707,  0.4858,  0.4544,  0.2782],\n",
       "        [-0.7204, -0.5583, -0.6109,  0.0922, -0.2144],\n",
       "        [-0.0677, -0.4301,  0.2895,  0.6176,  0.0414],\n",
       "        [-0.5260, -0.7050, -0.6042, -0.1023,  0.2385],\n",
       "        [-0.6395, -1.1409, -1.1408,  0.7629, -0.1346],\n",
       "        [-0.1931, -0.0516,  0.4576, -0.6535, -0.4288]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward the input from a specific depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.5741,  0.4155,  0.9535,  0.7903,  0.4239],\n",
       "        [-0.3347, -0.5885, -0.7607, -0.2467, -0.1851],\n",
       "        [-0.4663, -0.9943, -1.0202, -0.0491, -0.1571],\n",
       "        [ 0.2278,  0.3193,  0.5278, -0.2465, -0.2732]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcl(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient can back propagate to parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-1.4736,  5.7891,  3.8095, -1.4736,  5.7891,  3.8095, -3.2036,  2.4454,\n",
       "          3.3735, -3.2036,  2.4454,  3.3735, -0.3201,  2.4108,  0.9268, -0.3201,\n",
       "          2.4108,  0.9268], device='cuda:0'),\n",
       " tensor([20., 20., 10., 10.,  5.,  5.], device='cuda:0')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = gcl(x).sum()\n",
    "y.backward()\n",
    "[p.grad for p in gcl.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolution Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GraphConvNet` provides generic **non-linear causal maps** (maps that respect causality) by stacking multiple graph convolution layers (on the causal graph) and non-linear activation layers\n",
    "\n",
    "$$\\begin{split}\n",
    "\\zeta_a^{(0)} &= \\textsf{onehot}(z_a),\\\\\n",
    "\\zeta_a^{(k+1)} &= \\sum_{b\\to a} \\phi\\big(w_{e(b\\to a)}\\zeta_b^{(k)}+b_{e(b\\to a)}\\big)\\\\\n",
    "\\end{split}$$\n",
    "\n",
    "In theory, after infinite iterations, causal influences will propagate throughout the entire system, such that the output $\\zeta^{(n)}$ will be causally dependent on all variables $z_b$ which can affect $z_a$ within $n$ steps of causal influence.\n",
    "\n",
    "$$\\zeta_a^{(n)} = f(\\{z_b\\}_{b\\to\\cdots\\to a}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that $\\zeta_a^{(0)}$ is the one-hot encoding of the input configuration, if we treat $\\zeta_a^{(n)}$ as a score function, we can create a model for the conditional distribution\n",
    "\n",
    "$$\\ln p(z_a|\\{z_b\\}_{b\\to\\cdots\\to a}) = \\zeta_a^{(0)}\\cdot\\ln\\text{softmax}[\\zeta_a^{(n)}(\\{z_b\\}_{b\\to\\cdots\\to a})],$$\n",
    "\n",
    "which can be combined to establish an autoregressive model\n",
    "\n",
    "$$p(z)=\\prod_{a}p(z_a|\\{z_b\\}_{b\\to\\cdots\\to a}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "- `graph` (Graph) - causal graph (the unexpanded base graph) specifying the directed edges and edge types.\n",
    "- `features` (list of int) - number of features from input to hidden to output.\n",
    "- `bias` (bool) - whether or not to include bias\n",
    "- `nonlinearity` (str) - the nonlinear activation layer to use, specified by the layer name in `torch.nn`.\n",
    "\n",
    "**Properties:**\n",
    "- `layers` (ModuleList) - a list hosting `GraphConvLayer` and nonlinear activation layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comments*:\n",
    "* Note that the first layer should not have self-connections (otherwise the causal relation is no longer directed), but all subsequent layers are allow to have self-connections.\n",
    "* The node 0 is somewhat special, that it is always sampled independently from uniform distribution (one can see that it corresponds to the global symmetry of the spin model). It also has no causal relations with other nodes (a consequence of the Goldstone theorem: the order parameter should have zero excitation energy, thus it can not interact with other modes and hence can not establish any causal relation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward(x, depth=None, cache=None)` method implements the nonlinear multilayer graph convolution.\n",
    "- `forward(x)` without depth specification will forward the input together.\n",
    "- `forward(x, depth, cache)` will forward at a specific depth. For depth-specific forward, intermediate data will be cached. If the cache is not provided, the method will create a cache and returns it with the output, which should then be provided to the subsequent depth-specific forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/forward.png\" alt=\"forward\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: create a graph convolution network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphConvNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): GraphConvLayer(\n",
       "      in_features=2, out_features=4, bias=True, self_loop=False\n",
       "      Graph(4x4, 3 edges of 2 types)\n",
       "    )\n",
       "    (1): Tanh()\n",
       "    (2): GraphConvLayer(\n",
       "      in_features=4, out_features=3, bias=True, self_loop=1\n",
       "      Graph(4x4, 6 edges of 3 types)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn = GraphConvNet(Lattice(2, 2).causal_graph(), [2, 4, 3]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "         [-0.2935, -0.2522,  0.2858],\n",
       "         [ 0.0701, -0.7526, -0.0573],\n",
       "         [ 0.0932, -0.5417, -0.3421]]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,4,2).to(device)\n",
    "gcn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward by a specific depth. For depth-specific forward, the cache will be returned together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.2935, -0.2522,  0.2858],\n",
       "          [ 0.4987, -0.4220, -0.3123],\n",
       "          [ 0.4987, -0.4220, -0.3123]]], device='cuda:0',\n",
       "        grad_fn=<ViewBackward>),\n",
       " [torch.Size([8, 1]),\n",
       "  torch.Size([16, 1]),\n",
       "  torch.Size([16, 1]),\n",
       "  torch.Size([12, 1])])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, cache = gcn(x, 0)\n",
    "y, [c.shape for c in cache]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cache should be used for later depth-specific forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "          [-0.2935, -0.2522,  0.2858],\n",
       "          [ 0.0701, -0.7526, -0.0573],\n",
       "          [ 0.4581, -0.3964, -0.6755]]], device='cuda:0',\n",
       "        grad_fn=<ViewBackward>),\n",
       " [torch.Size([8, 1]),\n",
       "  torch.Size([16, 1]),\n",
       "  torch.Size([16, 1]),\n",
       "  torch.Size([12, 1])])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, cache = gcn(x, 1, cache)\n",
    "y, [c.shape for c in cache]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put together, one can foward by depth iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- depth: 0 ----\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "         [-0.2935, -0.2522,  0.2858],\n",
      "         [ 0.4987, -0.4220, -0.3123],\n",
      "         [ 0.4987, -0.4220, -0.3123]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "---- depth: 1 ----\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "         [-0.2935, -0.2522,  0.2858],\n",
      "         [ 0.0701, -0.7526, -0.0573],\n",
      "         [ 0.4581, -0.3964, -0.6755]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "---- depth: 2 ----\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "         [-0.2935, -0.2522,  0.2858],\n",
      "         [ 0.0701, -0.7526, -0.0573],\n",
      "         [ 0.0932, -0.5417, -0.3421]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "cache = None\n",
    "for depth in range(gcn.graph.max_depth+1):\n",
    "    y, cache = gcn(x, depth, cache)\n",
    "    print('---- depth: {} ----'.format(depth))\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the depth-wise forward and one-shot forward result in the same output (upto roundoff error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  3.7253e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00, -2.9802e-08]]], device='cuda:0',\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn(x) - y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient can back propagate to parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.6074,  2.2038,  0.0089,  0.0322,  0.4353,  1.5795,  0.0107,  0.0390,\n",
       "          0.6330,  0.4696,  0.2397,  0.1778,  0.5139,  0.3813, -0.2388, -0.1772],\n",
       "        device='cuda:0'),\n",
       " tensor([ 2.2446,  0.0328,  1.6087,  0.0397,  0.9287,  0.3516,  0.7539, -0.3503],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1142,  0.1749, -0.1665,  0.5369,  0.1142,  0.1749, -0.1665,  0.5369,\n",
       "          0.1142,  0.1749, -0.1665,  0.5369,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0132, -0.1192, -0.1378,  0.2089, -0.0132, -0.1192, -0.1378,  0.2089,\n",
       "         -0.0132, -0.1192, -0.1378,  0.2089], device='cuda:0'),\n",
       " tensor([3., 3., 3., 2., 2., 2., 1., 1., 1.], device='cuda:0')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum().backward()\n",
    "[p.grad for p in gcn.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoregressive model are usually named as \"pixel-...\" due to its element-wise sampling approach. The following \"...\" will be the neural network architecture used to model the conditional distribution. As we model the conditional distribution by graph convolutional network (GCN), it might be fair to call the resulting autoregressive model as a pixel-GCN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Autoregressive` combines lattice data with graph convolution network to create the autoregressive model. It provides methods to sample configurations and evalueate log probability. \n",
    "\n",
    "**Parameters:**\n",
    "- `lattice` (Lattice) - lattice system.\n",
    "- `num_classes` (int) - number of classes = group order.\n",
    "- `hidde_features` (list of int) - number of features for hidden layers.\n",
    "- `bias` (bool) - whether or not to include bias\n",
    "- `nonlinearity` (str) - the nonlinear activation layer to use, specified by the layer name in `torch.nn`.\n",
    "- `radius` (float) - the radius to specify the causal graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: create an autoregressive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoregressive(\n",
       "  (gcn): GraphConvNet(\n",
       "    (layers): ModuleList(\n",
       "      (0): GraphConvLayer(\n",
       "        in_features=2, out_features=4, bias=True, self_loop=False\n",
       "        Graph(4x4, 3 edges of 2 types)\n",
       "      )\n",
       "      (1): Tanh()\n",
       "      (2): GraphConvLayer(\n",
       "        in_features=4, out_features=2, bias=True, self_loop=1\n",
       "        Graph(4x4, 6 edges of 3 types)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = Autoregressive(Lattice(2, 2), SymmetricGroup(2).order, [4]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample(sample_size)` method generates samples. Gradient can not propagate back through sampling, because in-place update of the sample is involved in the generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [1., 0.]],\n",
       "\n",
       "        [[1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ar.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`log_prob(sample)` calculates the log probability of the sample by forwarding the sample once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7041, -2.8296], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob = ar.log_prob(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log probability supports gradient back propagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.1791,  0.0250,  0.2089, -0.1092, -0.2546,  0.4728, -0.0006,  0.0406,\n",
       "         -0.0385,  0.1674, -0.0315,  0.0738,  0.0504, -0.0440, -0.0632,  0.0261],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.2041,  0.0997,  0.2182,  0.0400,  0.1289,  0.0424,  0.0064, -0.0371],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.9185,  0.8317,  0.0832, -0.5207,  0.9185, -0.8317, -0.0832,  0.5207,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.5009,  0.3460,  0.1353, -0.4177,  0.5009, -0.3460, -0.1353,  0.4177],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1453, -0.1453,  0.0298, -0.0298,  0.1758, -0.1758], device='cuda:0')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob.sum().backward()\n",
    "[p.grad for p in ar.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages [*To be demonstrated yet*]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major innovation is to put the pixel-GCN in the holographic bulk and use it to model the distribution of the Haar wavelet encodings. What could be the advantage of this approach?\n",
    "\n",
    "* **Resolve the criticality**: the holographic mapping brings a scale-free system to a local system (with an emergnent scale set by the hyperbolic radius and the critical exponent). This can be seen from the correlation function of two spins of distance $r$ on the holographic boundary\n",
    "$$C(r)\\sim r^{-\\alpha} \\sim e^{-d/\\xi},$$\n",
    "where $d=R\\ln r$ is the geodesic distance through the bulk and $\\xi=R/\\alpha$ is an emerngent length scale. The complexity of modeling correlation at all scales is reduced to modeling correlations locally in the bulk. This arguement justifies our assumption that only limited number of local causal relations need to be considered. \n",
    "\n",
    "* **Shorten the causal chain**: conventional approach like pixel-CNN has unnatural causal structures (why a single pixel must causally depend on its upper-half-plane?). The natural way to think about generating a image is to start paining the outline first, then add the details. In this way, the scale itself becomes the emergent time of the generation process, which impose a natural causal structure in the holographic bulk. A remarkable feature is that the holographic bulk has a hyperbolic (tree-like) geometry, such that **time is short**, i.e. the causal chain is at most of the length $\\sim\\log L$ (logarithmic in system size), and the causal cone has limited width (like the past light cone in an expanding universe, which light can not catch up the collapse of universe if we look backwards). This greatly reduce the model complexity for large systems and enables more efficient sampling and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the dense version of autoregressive model, some connections outside the causal cone is removed. For example, the groups {8,9,10,11} and {12,13,14,15} have no direct mutual connections (their correlations are mediated by other nodes). More precisely speaking, they do have mutual information but they do not have *conditional* mutual information. This weakers the model, but that could be the price to pay for efficiency.\n",
    "\n",
    "| model     | connections     | parameters    |\n",
    "|-----------|-----------------|---------------|\n",
    "| dense     | $\\sim N^2$      | $\\sim N^2$    |\n",
    "| pixel-GCN | $\\sim N \\log N$ | $\\sim \\log N$ |\n",
    "| pixel-CNN | $\\sim N$        | $\\sim 1$      |\n",
    "| pixel-RNN | $\\sim N$        | $\\sim 1$      |\n",
    "\n",
    "Their performance should be further compared in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holographic Pixel GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HolographicPixelGNN` puts all components together to create the interface module.\n",
    "\n",
    "**Parameters:**\n",
    "- `model` (Model) - energy model containing information of lattice, group and Hamiltonian.\n",
    "- `hidde_features` (list of int) - number of features for hidden layers.\n",
    "- `bias` (bool) - whether or not to include bias\n",
    "- `nonlinearity` (str) - the nonlinear activation layer to use, specified by the layer name in `torch.nn`.\n",
    "- `radius` (float) - the radius to specify the causal graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a holographic pixel-GNN model. It has the following components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HolographicPixelGNN(\n",
       "  (model): Model(\n",
       "    (lattice): Lattice(2x2 grid)\n",
       "    (group): Group(order=2)\n",
       "    (energy): EnergyTerms(\n",
       "      (0): TwoBody(G -> [-0.5, 0.5] across [1, 0])\n",
       "      (1): TwoBody(G -> [-0.5, 0.5] across [0, 1])\n",
       "    )\n",
       "  )\n",
       "  (generator): Autoregressive(\n",
       "    (gcn): GraphConvNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): GraphConvLayer(\n",
       "          in_features=2, out_features=3, bias=True, self_loop=False\n",
       "          Graph(4x4, 3 edges of 2 types)\n",
       "        )\n",
       "        (1): Tanh()\n",
       "        (2): GraphConvLayer(\n",
       "          in_features=3, out_features=2, bias=True, self_loop=1\n",
       "          Graph(4x4, 6 edges of 3 types)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = HolographicPixelGNN(Model(H(0.5), Lattice(2, 2), SymmetricGroup(2)), hidden_features = [3]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw samples from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1],\n",
       "         [1, 0]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [0, 0]]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.sample(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate log probabilities of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.8696, -2.3435], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_prob(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate energies of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.energy(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasnform the samples to Haar wavelet configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 1],\n",
       "        [0, 0, 1, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.haar.inv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loss(sample_size)` method calculates the loss function over a set of samples specified by the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3887, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model.loss(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient can propagate back to parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.3909,  0.2479,  0.0942,  0.0597, -0.4486, -0.4112,  0.0793,  0.1341,\n",
       "          0.0144,  0.0255, -0.0770, -0.2184], device='cuda:0'),\n",
       " tensor([ 0.6388,  0.1539, -0.8598,  0.2134,  0.0398, -0.2954], device='cuda:0'),\n",
       " tensor([ 0.1589,  0.2060, -0.0349, -0.1589, -0.2060,  0.0349,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0396,  0.0401,  0.0323, -0.0396,\n",
       "         -0.0401, -0.0323], device='cuda:0'),\n",
       " tensor([-1.5194,  1.5194, -1.0137,  1.0137, -0.3542,  0.3542], device='cuda:0')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "[p.grad for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reverse KL with log-trick**. The goal is to minimize the difference between the model distribution $q_\\theta(x)$ and the target distribution $p(x) \\propto e^{-E(x)}$ by minimizing the reverse KL divergence (see [Wu, Wang, Zhang 2019](https://arxiv.org/pdf/1809.10606.pdf) for more details)\n",
    "\n",
    "$$\\begin{split}\\mathcal{L}&=\\mathsf{KL}(q_\\theta||p)\\\\\n",
    "&=\\sum_{x} q_\\theta(x) \\ln \\frac{q_\\theta(x)}{p(x)}\\\\\n",
    "&=\\sum_{x}q_\\theta(x)(E(x)+\\ln q_\\theta(x)). \n",
    "\\end{split}$$\n",
    "\n",
    "All the parameter dependence is in the model distribution $q_\\theta$. The gradient of the loss function with respect to the parameters is given by\n",
    "\n",
    "$$\\begin{split}\\partial_\\theta\\mathcal{L}&= \\partial_\\theta \\sum_{x}q_\\theta(x)(E(x)+\\ln q_\\theta(x))\\\\\n",
    "&= \\sum_{x}[(\\partial_\\theta q_\\theta(x))(E(x)+\\ln q_\\theta(x))+q_\\theta(x)\\partial_\\theta \\ln q_\\theta(x)]\\\\\n",
    "\\end{split}$$\n",
    "\n",
    "The last term can be dropped because\n",
    "\n",
    "$$\\sum_x q_\\theta(x)\\partial_\\theta \\ln q_\\theta(x) = \\sum_x \\partial_\\theta q_\\theta(x)=\\partial_\\theta\\sum_x q_\\theta(x)=\\partial_\\theta 1 = 0,$$\n",
    "\n",
    "the remaining term reads\n",
    "\n",
    "$$\\begin{split}\\partial_\\theta\\mathcal{L}&= \\sum_{x}(\\partial_\\theta q_\\theta(x))(E(x)+\\ln q_\\theta(x))\\\\\n",
    "&= \\sum_{x}(\\partial_\\theta q_\\theta(x))R(x)\\\\\n",
    "&= \\mathbb{E}_{x\\sim q_\\theta}(\\partial_\\theta \\ln q_\\theta(x))R(x)\\\\\n",
    "\\end{split}$$\n",
    "\n",
    "with a reward signal $R(x)=E(x)+\\ln q_\\theta(x)$ in the context of reinforcement learning. The gradient signal $\\partial_\\theta \\ln q_\\theta(x)$ is weighted by $R(x)$, such that when $R(x)$ is large for a configuration $x$, the gradient descent will decrease the log likelihood $\\ln q_\\theta(x)$ for that configuration, hence the optimzation will try to reduce the free energy.\n",
    "\n",
    "However we should not just drop the last term for finite batches, instead we should introduce a Lagrangian multiplier to balance unphysical the gradient signal that tries to change the normalization of $q_\\theta$. This amounts to subtracting $R(x)$ by a baseline value $b=\\mathbb{E}_{x\\sim q_\\theta} R(x)$, which can be estimated within each batch. The baseline subtraction helps to reduce the variance of the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a model and link to an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"model.py\"\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = HolographicPixelGNN(Model(H(0.440686793), Lattice(4, 2), SymmetricGroup(2)), \n",
    "                            hidden_features = [8, 8], radius = 1.5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.2314, free energy: -14.7981   0.7171\n",
      "  200 loss:   0.0825, free energy: -15.1021   0.5016\n",
      "  300 loss:   0.0591, free energy: -15.2293   0.4914\n",
      "  400 loss:   0.0678, free energy: -15.3115   0.4409\n",
      "  500 loss:   0.0574, free energy: -15.3446   0.4095\n",
      "  600 loss:   0.0264, free energy: -15.3584   0.3960\n",
      "  700 loss:   0.0453, free energy: -15.3710   0.3856\n",
      "  800 loss:   0.0482, free energy: -15.3783   0.3955\n",
      "  900 loss:   0.0433, free energy: -15.3670   0.3856\n",
      " 1000 loss:   0.0432, free energy: -15.3751   0.3675\n",
      " 1100 loss:   0.0210, free energy: -15.3802   0.3589\n",
      " 1200 loss:   0.0582, free energy: -15.3893   0.3818\n",
      " 1300 loss:   0.0410, free energy: -15.4078   0.3516\n",
      " 1400 loss:   0.0033, free energy: -15.4208   0.3344\n",
      " 1500 loss:   0.0652, free energy: -15.4009   0.3858\n",
      " 1600 loss:   0.0442, free energy: -15.4287   0.3289\n",
      " 1700 loss:   0.0191, free energy: -15.4189   0.3643\n",
      " 1800 loss:   0.0288, free energy: -15.4320   0.3271\n",
      " 1900 loss:   0.0473, free energy: -15.4225   0.3835\n",
      " 2000 loss:   0.0363, free energy: -15.4267   0.3617\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "for k in range(2000):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} {:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model converges to a free energy of -15.42, while the exact value is -15.52. The relative error is about 0.6%. It seems that this has saturated the representation power of the pixel-GCN. What is the cause of the mismatch? How to improve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempts to Improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extend the Causal Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One conjecture is that the loss is due to the missing causal connections. We can complete the causal connections and retrain. The causal graph scales with radius as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 1.0: Graph(16x16, 51 edges of 7 types), max_depth = 5\n",
      "r = 1.2: Graph(16x16, 67 edges of 9 types), max_depth = 7\n",
      "r = 1.5: Graph(16x16, 85 edges of 9 types), max_depth = 10\n",
      "r = 2.0: Graph(16x16, 101 edges of 9 types), max_depth = 12\n",
      "r = 3.0: Graph(16x16, 105 edges of 9 types), max_depth = 14\n",
      "r = 5.0: Graph(16x16, 105 edges of 9 types), max_depth = 14\n"
     ]
    }
   ],
   "source": [
    "latt = Lattice(4, 2)\n",
    "for r in [1.,1.2,1.5,2.,3.,5.]:\n",
    "    graph = latt.causal_graph(r)\n",
    "    print('r = {}: {}, max_depth = {}'.format(r, graph, graph.max_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $r>3$ the causal relation is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"model.py\"\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = HolographicPixelGNN(Model(H(0.440686793), Lattice(4, 2), SymmetricGroup(2)), \n",
    "                            hidden_features = [8, 8], radius = 3.).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.4596, free energy: -14.6877   0.8562\n",
      "  200 loss:   0.0217, free energy: -15.1392   0.4337\n",
      "  300 loss:   0.0867, free energy: -15.1900   0.3865\n",
      "  400 loss:   0.0949, free energy: -15.1332   0.4544\n",
      "  500 loss:   0.1035, free energy: -15.2369   0.4765\n",
      "  600 loss:   0.0407, free energy: -15.3104   0.4476\n",
      "  700 loss:   0.0558, free energy: -15.3249   0.4105\n",
      "  800 loss:   0.0513, free energy: -15.3621   0.3938\n",
      "  900 loss:   0.0345, free energy: -15.3556   0.4020\n",
      " 1000 loss:   0.0569, free energy: -15.3631   0.4116\n",
      " 1100 loss:   0.0722, free energy: -15.3677   0.4034\n",
      " 1200 loss:   0.0523, free energy: -15.3754   0.3992\n",
      " 1300 loss:   0.0702, free energy: -15.3546   0.4190\n",
      " 1400 loss:   0.0262, free energy: -15.3819   0.3673\n",
      " 1500 loss:   0.0572, free energy: -15.3878   0.3633\n",
      " 1600 loss:   0.0976, free energy: -15.3410   0.4291\n",
      " 1700 loss:   0.0478, free energy: -15.3749   0.4134\n",
      " 1800 loss:   0.0572, free energy: -15.3956   0.3828\n",
      " 1900 loss:   0.0428, free energy: -15.3947   0.3773\n",
      " 2000 loss:   0.0632, free energy: -15.3971   0.3891\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "for k in range(2000):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} {:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance even worse, trains slowly and trapped by local minimum. Probabily the causal connection is not the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is to increase the number of hidden features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"model.py\"\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = HolographicPixelGNN(Model(H(0.440686793), Lattice(4, 2), SymmetricGroup(2)), \n",
    "                            hidden_features = [12, 12], radius = 1.5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:   0.0523, free energy: -15.4052   0.4019\n",
      "  200 loss:   0.0535, free energy: -15.4066   0.3529\n",
      "  300 loss:   0.0543, free energy: -15.4080   0.3700\n",
      "  400 loss:   0.0546, free energy: -15.4276   0.3403\n",
      "  500 loss:   0.0726, free energy: -15.4121   0.3731\n",
      "  600 loss:   0.0598, free energy: -15.3932   0.3839\n",
      "  700 loss:   0.0798, free energy: -15.3742   0.4184\n",
      "  800 loss:   0.0671, free energy: -15.4210   0.3666\n",
      "  900 loss:   0.0499, free energy: -15.4031   0.3581\n",
      " 1000 loss:   0.0849, free energy: -15.3191   0.5003\n",
      " 1100 loss:   0.0813, free energy: -15.3735   0.4123\n",
      " 1200 loss:   0.0528, free energy: -15.3977   0.4044\n",
      " 1300 loss:   0.1155, free energy: -15.3743   0.4518\n",
      " 1400 loss:   0.0703, free energy: -15.4000   0.3780\n",
      " 1500 loss:   0.0869, free energy: -15.4088   0.4005\n",
      " 1600 loss:   0.0436, free energy: -15.4161   0.3595\n",
      " 1700 loss:   0.0326, free energy: -15.4157   0.3538\n",
      " 1800 loss:   0.0654, free energy: -15.4120   0.3888\n",
      " 1900 loss:   0.0463, free energy: -15.3908   0.4149\n",
      " 2000 loss:   0.1147, free energy: -15.3897   0.4025\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "for k in range(2000):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} {:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is almost no improvement. But it becomes easier to be trapped at local minimum, and coverges more slowly. If we further increase the number of features, the performance could get even worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increase the Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"model.py\"\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = HolographicPixelGNN(Model(H(0.440686793), Lattice(4, 2), SymmetricGroup(2)), \n",
    "                            hidden_features = [8, 8], radius = 1.5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.1804, free energy: -14.9131   0.7236\n",
      "  200 loss:   0.0854, free energy: -15.3049   0.4273\n",
      "  300 loss:   0.0138, free energy: -15.3876   0.3390\n",
      "  400 loss:   0.0017, free energy: -15.4102   0.3071\n",
      "  500 loss:   0.0004, free energy: -15.4262   0.3081\n",
      "  600 loss:   0.0254, free energy: -15.4250   0.3149\n",
      "  700 loss:   0.0082, free energy: -15.4388   0.2856\n",
      "  800 loss:   0.0130, free energy: -15.4397   0.3010\n",
      "  900 loss:   0.0179, free energy: -15.4424   0.3159\n",
      " 1000 loss:   0.0087, free energy: -15.4515   0.2902\n",
      " 1100 loss:   0.0230, free energy: -15.4520   0.3067\n",
      " 1200 loss:   0.0058, free energy: -15.4580   0.3007\n",
      " 1300 loss:   0.0154, free energy: -15.4627   0.3004\n",
      " 1400 loss:   0.0119, free energy: -15.4672   0.2909\n",
      " 1500 loss:   0.0126, free energy: -15.4681   0.2767\n",
      " 1600 loss:   0.0053, free energy: -15.4713   0.2700\n",
      " 1700 loss:   0.0069, free energy: -15.4740   0.2747\n",
      " 1800 loss:   0.0061, free energy: -15.4748   0.2642\n",
      " 1900 loss:   0.0118, free energy: -15.4748   0.2720\n",
      " 2000 loss:   0.0099, free energy: -15.4772   0.2651\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "for k in range(2000):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} {:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the batch size could further improve the result slightly. But this is a little cheating as we have allowed machine to sample more configurations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increase the Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"model.py\"\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = HolographicPixelGNN(Model(H(0.440686793), Lattice(4, 2), SymmetricGroup(2)), \n",
    "                            hidden_features = [8, 8, 8, 8], radius = 1.5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.0993, free energy: -14.8069   0.5581\n",
      "  200 loss:   0.0333, free energy: -15.0457   0.2860\n",
      "  300 loss:   0.0182, free energy: -15.0470   0.2752\n",
      "  400 loss:   0.0444, free energy: -15.0451   0.2793\n",
      "  500 loss:   0.0230, free energy: -15.0531   0.2365\n",
      "  600 loss:   0.0616, free energy: -15.0444   0.3277\n",
      "  700 loss:   0.0586, free energy: -15.0440   0.2984\n",
      "  800 loss:   0.0244, free energy: -15.0547   0.2376\n",
      "  900 loss:   0.0130, free energy: -15.0530   0.2245\n",
      " 1000 loss:   0.0399, free energy: -15.0602   0.2846\n",
      " 1100 loss:   0.0413, free energy: -15.0463   0.2617\n",
      " 1200 loss:   0.0755, free energy: -15.0242   0.3260\n",
      " 1300 loss:   0.0364, free energy: -15.0533   0.2478\n",
      " 1400 loss:   0.0334, free energy: -15.0512   0.2704\n",
      " 1500 loss:   0.0471, free energy: -15.0344   0.2870\n",
      " 1600 loss:   0.0297, free energy: -15.0531   0.2666\n",
      " 1700 loss:   0.0432, free energy: -14.8294   0.1105\n",
      " 1800 loss:   0.0746, free energy: -14.9274   0.2421\n",
      " 1900 loss:   0.0463, free energy: -15.0431   0.2788\n",
      " 2000 loss:   0.0311, free energy: -15.0471   0.2309\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "for k in range(2000):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} {:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trapped at local minimum and the performance gets worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling a single training iteration with snakeviz. Sampling takes the most time. How to improve that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"model.py\"\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = HolographicPixelGNN(Model(H(0.440686793), Lattice(4, 2), SymmetricGroup(2)), \n",
    "                            hidden_features = [8, 8], radius = 1.5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file '/var/folders/1m/3nz1kxmj2mgb2s2gwq2ndxqh0000gn/T/tmp84901dlh'. \n",
      "Embedding SnakeViz in this document...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe id='snakeviz-0c3ea494-86fe-11eb-a034-acde48001122' frameborder=0 seamless width='100%' height='1000'></iframe>\n",
       "<script>document.getElementById(\"snakeviz-0c3ea494-86fe-11eb-a034-acde48001122\").setAttribute(\"src\", \"http://\" + document.location.hostname + \":8080/snakeviz/%2Fvar%2Ffolders%2F1m%2F3nz1kxmj2mgb2s2gwq2ndxqh0000gn%2FT%2Ftmp84901dlh\")</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%snakeviz\n",
    "batch_size = 100\n",
    "loss = model.loss(batch_size)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.sample(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1,0)-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8378, 0.8263, 0.8380, 0.8232],\n",
       "        [0.8351, 0.7778, 0.8122, 0.7820],\n",
       "        [0.8344, 0.8210, 0.8385, 0.8146],\n",
       "        [0.8455, 0.7819, 0.8168, 0.7844]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = tuple(range(-model.energy.lattice.dimension,0))\n",
    "rolled = model.energy.group.inv(x.roll((-1,0), dims))\n",
    "coupled = model.energy.group.mul(rolled, x)\n",
    "corr = model.energy.group.val(coupled, torch.tensor([1.,-1.]))\n",
    "corr.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0,1)-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8518, 0.8516, 0.8547, 0.8490],\n",
       "        [0.8358, 0.8342, 0.8493, 0.8247],\n",
       "        [0.8424, 0.8389, 0.8473, 0.8344],\n",
       "        [0.8323, 0.8283, 0.8395, 0.8255]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = tuple(range(-model.energy.lattice.dimension,0))\n",
    "rolled = model.energy.group.inv(x.roll((0,-1), dims))\n",
    "coupled = model.energy.group.mul(rolled, x)\n",
    "corr = model.energy.group.val(coupled, torch.tensor([1.,-1.]))\n",
    "corr.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that the correlation is not translationally symmetric. This might be the main source of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restore the translation symmetry, one idea is to symmetrize the sample by random translations. This amounts to model the target probability $p(x)$ by a mixtrue model\n",
    "$$q_\\theta(x) = \\frac{1}{N}\\sum_a q_\\theta(x+a),$$\n",
    "where $a$ is summed over the translation group of the lattice and $N$ is the order of the translation group.\n",
    "\n",
    "The loss function becomes\n",
    "$$\\mathcal{L}=\\sum_x \\Big(\\frac{1}{N}\\sum_a q_\\theta(x+a)\\Big)\\bigg(E(x)+\\ln \\Big(\\frac{1}{N}\\sum_a q_\\theta(x+a)\\Big)\\bigg).$$\n",
    "Using the inequality\n",
    "$$\\Big(\\frac{1}{N}\\sum_a q_\\theta(x+a)\\Big)\\ln \\Big(\\frac{1}{N}\\sum_a q_\\theta(x+a)\\Big)\\leq \\frac{1}{N}\\sum_a q_\\theta(x+a)\\ln q_\\theta(x+a),$$\n",
    "the loss function can be bounded by \n",
    "$$\\mathcal{L}\\leq \\frac{1}{N}\\sum_a\\sum_x  q_\\theta(x+a)\\big(E(x)+\\ln q_\\theta(x+a)\\big)\\equiv \\bar{\\mathcal{L}}.$$\n",
    "By brining $\\mathcal{L}$ towards zero, the actual loss will also approach to zero.\n",
    "\n",
    "Using the summation of $x$, we can redefine $x+a = x$, such that\n",
    "$$\\bar{\\mathcal{L}}=\\frac{1}{N}\\sum_a\\sum_x  q_\\theta(x)\\big(E(x-a)+\\ln q_\\theta(x)\\big)=\\sum_x  q_\\theta(x)\\big(E(x)+\\ln q_\\theta(x)\\big).$$\n",
    "The loss function actually remains the same, because the energy function is symmetric under translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"model.py\"\n",
    "H = lambda J: -J*(TwoBody(torch.tensor([1.,-1.]), (1,0)) \n",
    "                  + TwoBody(torch.tensor([1.,-1.]), (0,1)))\n",
    "model = HolographicPixelGNN(\n",
    "            Model(\n",
    "                H(0.440686793), # Ising critical point\n",
    "                SymmetricGroup(2), \n",
    "                Lattice(4, 2)), \n",
    "            hidden_features = [4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss: -128.0252, free energy: -14.3258\n",
      "  200 loss:  -9.1453, free energy: -15.2334\n",
      "  300 loss:   3.0321, free energy: -15.2826\n",
      "  400 loss:   0.0435, free energy: -15.2954\n",
      "  500 loss:  -1.6938, free energy: -15.3154\n",
      "  600 loss:   0.3055, free energy: -15.3347\n",
      "  700 loss:  -3.3122, free energy: -15.3460\n",
      "  800 loss:  -0.0673, free energy: -15.3751\n",
      "  900 loss:  -3.4675, free energy: -15.3795\n",
      " 1000 loss:  -2.2874, free energy: -15.3904\n",
      " 1100 loss:  -5.7892, free energy: -15.3803\n",
      " 1200 loss:  -4.3349, free energy: -15.3864\n",
      " 1300 loss:  -2.3260, free energy: -15.3953\n",
      " 1400 loss:  -1.9631, free energy: -15.4171\n",
      " 1500 loss:  -3.2912, free energy: -15.4215\n",
      " 1600 loss:  -2.9325, free energy: -15.4262\n",
      " 1700 loss:  -0.6374, free energy: -15.4272\n",
      " 1800 loss:  -1.5955, free energy: -15.4323\n",
      " 1900 loss:  -1.7919, free energy: -15.4271\n",
      " 2000 loss:   1.2615, free energy: -15.4353\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_loss = 0.\n",
    "free_energy = 0.\n",
    "echo = 100\n",
    "for epoch in range(2000):\n",
    "    x = model.sample(batch_size)\n",
    "    log_prob = model.log_prob(x)\n",
    "    energy = model.energy(x)\n",
    "    free = energy + log_prob.detach()\n",
    "    meanfree = free.mean()\n",
    "    loss = torch.sum(log_prob * (free - meanfree))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    free_energy += meanfree.item()\n",
    "    if (epoch+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f}'.format(epoch+1, train_loss/echo, free_energy/echo))\n",
    "        train_loss = 0.\n",
    "        free_energy = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-15.5328, -15.4791, -15.4780, -15.4704, -15.4916, -15.5104, -15.4654,\n",
      "        -15.4926, -15.4941, -15.5059, -15.5071, -15.5008, -15.4807, -15.5108,\n",
      "        -15.4884, -15.5086, -15.4986, -15.4825, -15.4900, -15.4779, -15.5024,\n",
      "        -15.5043, -15.4846, -15.5295, -15.4797, -15.4762, -15.4834, -15.4789,\n",
      "        -15.5423, -15.5269, -15.4888, -15.4732, -15.5243, -15.5040, -15.4393,\n",
      "        -15.4942, -15.4827, -15.4778, -15.4804, -15.5104, -15.4958, -15.5068,\n",
      "        -15.4886, -15.4729, -15.4854, -15.4967, -15.4322, -15.5044, -15.4833,\n",
      "        -15.4693, -15.5313, -15.4983, -15.4741, -15.5354, -15.5384, -15.4687,\n",
      "        -15.4930, -15.4858, -15.5021, -15.5568, -15.5000, -15.4812, -15.4534,\n",
      "        -15.4874, -15.4596, -15.5264, -15.4516, -15.4621, -15.4797, -15.4916,\n",
      "        -15.5320, -15.5010, -15.5241, -15.4993, -15.4920, -15.4831, -15.4822,\n",
      "        -15.4846, -15.5249, -15.4885, -15.5109, -15.4655, -15.4739, -15.5028,\n",
      "        -15.4846, -15.5289, -15.4891, -15.4938, -15.5611, -15.4905, -15.4938,\n",
      "        -15.4753, -15.4898, -15.4914, -15.4969, -15.4953, -15.4756, -15.5197,\n",
      "        -15.4749, -15.5142])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(-15.4940), tensor(0.0230))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    F = []\n",
    "    for i in range(echo):\n",
    "        F.append(model.free_energy(model.sample(batch_size), rot=False).mean())\n",
    "F = torch.tensor(F)\n",
    "print(F)\n",
    "F.mean(), F.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is significantly improved. Using the mixture model estimation, the variational free energy can reach -15.49, which is 0.2% above -15.52."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the main issue is the training efficiency. Consider\n",
    "* removing the layer norm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
