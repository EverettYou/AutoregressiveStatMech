{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `%r` as an alias for `%run model.py`.\n"
     ]
    }
   ],
   "source": [
    "%alias_magic r run -p \"model.py\"\n",
    "%r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel Graph Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lattice System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a flat lattice. List the nodes and their center coordinates.\n",
    "- **relevant nodes**: the preceeding nodes within a given radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind   center   relevant_nodes\n",
      "  0 [0.0, 0.0] []\n",
      "  1 [0.0, 1.0] [0]\n",
      "  2 [0.0, 2.0] [1]\n",
      "  3 [0.0, 3.0] [2, 0]\n",
      "  4 [1.0, 0.0] [0, 3, 1]\n",
      "  5 [1.0, 1.0] [4, 2, 0, 1]\n",
      "  6 [1.0, 2.0] [2, 5, 3, 1]\n",
      "  7 [1.0, 3.0] [0, 2, 3, 4, 6]\n",
      "  8 [2.0, 0.0] [4, 7, 5]\n",
      "  9 [2.0, 1.0] [4, 5, 8, 6]\n",
      " 10 [2.0, 2.0] [9, 7, 5, 6]\n",
      " 11 [2.0, 3.0] [10, 4, 6, 7, 8]\n",
      " 12 [3.0, 0.0] [9, 0, 1, 11, 3, 8]\n",
      " 13 [3.0, 1.0] [9, 0, 1, 10, 2, 12, 8]\n",
      " 14 [3.0, 2.0] [9, 10, 1, 11, 2, 3, 13]\n",
      " 15 [3.0, 3.0] [0, 10, 11, 2, 3, 12, 14, 8]\n"
     ]
    }
   ],
   "source": [
    "latt = FlatLattice(4, 2)\n",
    "print('ind   center   relevant_nodes')\n",
    "for node in latt.nodes:\n",
    "    if node.type is 'lat':\n",
    "        print(' {:2d} {} {}'.format(node.ind, \n",
    "                                 node.center.tolist(),\n",
    "                                 [node.ind for node in latt.relevant_nodes(node, 2.)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nodes are arranged on a square lattice with periodic boundary condition.\n",
    "\n",
    "<img src=\"./image/flat.png\" alt=\"flat\" width=\"180\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the causal graph from the lattice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: (0, 1), 2: (1, 1)},\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [2, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [2, 0, 2, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 2, 0, 2, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0],\n",
       "         [2, 1, 2, 0, 0, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0, 0],\n",
       "         [0, 2, 1, 2, 0, 0, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0],\n",
       "         [2, 0, 2, 1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 1, 0]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = latt.causal_graph()\n",
    "graph.type_dict, graph.source_depths, graph.adjacency_matrix().to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the causal graph scales with the radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 1.01: Graph(16x16, 32 edges of 1 types), max_depth = 6\n",
      "r = 1.42: Graph(16x16, 64 edges of 2 types), max_depth = 15\n",
      "r = 2.01: Graph(16x16, 80 edges of 3 types), max_depth = 15\n",
      "r = 2.24: Graph(16x16, 112 edges of 4 types), max_depth = 15\n",
      "r = 2.83: Graph(16x16, 120 edges of 5 types), max_depth = 15\n"
     ]
    }
   ],
   "source": [
    "for r in [1.01,1.42,2.01,2.24,2.83]:\n",
    "    graph = latt.causal_graph(radius=r)\n",
    "    print('r = {}: {}, max_depth = {}'.format(r, graph, graph.max_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tree lattice. List the nodes and their center coordinates.\n",
    "- **relevant nodes**: the preceeding nodes within the past light-cone of nodes in a given radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind   center   relevant_nodes\n",
      "  0            []\n",
      "  1 [2.0, 2.0] []\n",
      "  2 [1.0, 2.0] [1]\n",
      "  3 [3.0, 2.0] [2, 1]\n",
      "  4 [1.0, 1.0] [3, 2, 1]\n",
      "  5 [3.0, 1.0] [4, 3, 2, 1]\n",
      "  6 [1.0, 3.0] [4, 5, 2, 3, 1]\n",
      "  7 [3.0, 3.0] [6, 4, 5, 2, 3, 1]\n",
      "  8 [0.5, 1.0] [6, 4, 5, 2, 3, 1, 7]\n",
      "  9 [2.5, 1.0] [6, 4, 5, 2, 3, 1, 7, 8]\n",
      " 10 [0.5, 3.0] [6, 4, 5, 2, 3, 1, 7, 8]\n",
      " 11 [2.5, 3.0] [6, 4, 5, 9, 2, 3, 1, 10, 7]\n",
      " 12 [1.5, 1.0] [6, 4, 5, 9, 11, 2, 3, 1, 10, 7, 8]\n",
      " 13 [3.5, 1.0] [6, 4, 5, 9, 11, 2, 12, 3, 1, 10, 7, 8]\n",
      " 14 [1.5, 3.0] [6, 4, 5, 9, 11, 2, 12, 3, 1, 10, 7, 8]\n",
      " 15 [3.5, 3.0] [6, 4, 5, 14, 9, 11, 2, 3, 13, 1, 10, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "latt = TreeLattice(4, 2)\n",
    "print('ind   center   relevant_nodes')\n",
    "for node in latt.nodes:\n",
    "    if node.type is 'lat':\n",
    "        print(' {:2d} {} {}'.format(node.ind, \n",
    "                                 node.center.tolist() if node.center is not None else '          ',\n",
    "                                 [node.ind for node in latt.relevant_nodes(node, 2.)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent nodes are arranged in on a binary tree representing the hierachical structure.\n",
    "\n",
    "<img src=\"./image/tree.png\" alt=\"tree\" width=\"180\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the causal graph from the lattice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: (0, 1, 1),\n",
       "  2: (0, 3, 3),\n",
       "  3: (0, 0, 2),\n",
       "  4: (0, 2, 3),\n",
       "  5: (2, 1, 1),\n",
       "  6: (0, 0, 1),\n",
       "  7: (1, 0, 1),\n",
       "  8: (0, 1, 3),\n",
       "  9: (2, 0, 1),\n",
       "  10: (1, 0, 2),\n",
       "  11: (0, 0, 3)},\n",
       " tensor([0, 0, 1, 2, 2, 3, 2, 3, 3, 4, 3, 4, 5, 5, 5, 5]),\n",
       " tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  3,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  3,  0,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  3,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  3,  0,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 11, 10,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 11,  0, 10,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 11, 10,  0,  0,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 11,  0, 10,  0,  0,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 11, 10,  8,  9,  4,  0,  0,  5,  2,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 11,  8, 10,  4,  9,  0,  0,  2,  5,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 11, 10,  8,  0,  0,  9,  4,  0,  0,  5,  2,  0,  0,  0,  0],\n",
       "         [ 0, 11,  8, 10,  0,  0,  4,  9,  0,  0,  2,  5,  0,  0,  0,  0]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = latt.causal_graph()\n",
    "graph.type_dict, graph.source_depths, graph.adjacency_matrix().to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the causal graph scales with the radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 1.0: Graph(16x16, 51 edges of 11 types), max_depth = 5\n",
      "r = 1.2: Graph(16x16, 67 edges of 14 types), max_depth = 7\n",
      "r = 1.5: Graph(16x16, 85 edges of 16 types), max_depth = 10\n",
      "r = 2.0: Graph(16x16, 101 edges of 16 types), max_depth = 12\n",
      "r = 3.0: Graph(16x16, 105 edges of 16 types), max_depth = 14\n"
     ]
    }
   ],
   "source": [
    "for r in [1., 1.2, 1.5, 2., 3.]:\n",
    "    graph = latt.causal_graph(radius=r)\n",
    "    print('r = {}: {}, max_depth = {}'.format(r, graph, graph.max_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the model and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = Model(H(0.440686793), FlatLattice(4, 2), SymmetricGroup(2))\n",
    "model = PixelGNN(model, hidden_features=[8, 8], radius=2.01).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -1.0314, free energy: -14.0495 ±  1.3977\n",
      "  200 loss:  -0.2964, free energy: -15.4287 ±  0.4349\n",
      "  300 loss:  -0.1251, free energy: -15.4752 ±  0.3027\n",
      "  400 loss:  -0.0872, free energy: -15.4799 ±  0.2845\n",
      "  500 loss:  -0.0921, free energy: -15.4883 ±  0.2572\n",
      "  600 loss:  -0.0813, free energy: -15.4918 ±  0.2443\n",
      "  700 loss:  -0.0691, free energy: -15.4933 ±  0.2378\n",
      "  800 loss:  -0.0669, free energy: -15.4978 ±  0.2255\n",
      "  900 loss:  -0.0496, free energy: -15.4873 ±  0.2594\n",
      " 1000 loss:  -0.0634, free energy: -15.4992 ±  0.2161\n",
      " 1100 loss:  -0.0598, free energy: -15.4997 ±  0.2098\n",
      " 1200 loss:  -0.0572, free energy: -15.5002 ±  0.2120\n",
      " 1300 loss:  -0.0588, free energy: -15.5011 ±  0.2101\n",
      " 1400 loss:  -0.0527, free energy: -15.4988 ±  0.2149\n",
      " 1500 loss:  -0.0535, free energy: -15.4987 ±  0.2171\n",
      " 1600 loss:  -0.0532, free energy: -15.4995 ±  0.2146\n",
      " 1700 loss:  -0.0554, free energy: -15.5014 ±  0.2067\n",
      " 1800 loss:  -0.0544, free energy: -15.4999 ±  0.2139\n",
      " 1900 loss:  -0.0536, free energy: -15.5002 ±  0.2102\n",
      " 2000 loss:  -0.0474, free energy: -15.4980 ±  0.2204\n",
      "total time: 147.43s,  73.71ms per step.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 5000\n",
    "steps = 2000\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "tic = time.time()\n",
    "for k in range(steps):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} ±{:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "toc = time.time()\n",
    "print('total time: {:6.2f}s, {:6.2f}ms per step.'.format(toc-tic, (toc-tic)/steps*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short-range correlation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7922, 0.8011, 0.7962, 0.7861],\n",
      "        [0.7895, 0.7803, 0.7835, 0.7775],\n",
      "        [0.7928, 0.7822, 0.7800, 0.7827],\n",
      "        [0.7908, 0.7867, 0.7837, 0.7776]], device='cuda:0')\n",
      "tensor([[0.7961, 0.7879, 0.7702, 0.7936],\n",
      "        [0.7677, 0.7791, 0.7711, 0.7658],\n",
      "        [0.7603, 0.7586, 0.7709, 0.7668],\n",
      "        [0.7767, 0.7789, 0.7767, 0.7747]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = model.sample(100000);\n",
    "dims = tuple(range(-model.model.lattice.dimension,0))\n",
    "for shift in [(-1,0), (0,-1)]:\n",
    "    rolled = model.model.group.inv(x.roll(shift, dims))\n",
    "    coupled = model.model.group.mul(rolled, x)\n",
    "    corr = model.model.group(coupled, torch.tensor([1.,-1.]))\n",
    "    print(corr.mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Lattice (With Scale-Invariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the model and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = Model(H(0.440686793), TreeLattice(4, 2), SymmetricGroup(2))\n",
    "model = PixelGNN(model, hidden_features=[8, 8], radius=1.5, scale_invariance=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.0008, free energy: -15.4908 ±  0.2219\n",
      "  200 loss:  -0.0008, free energy: -15.4872 ±  0.2299\n",
      "  300 loss:  -0.0027, free energy: -15.4941 ±  0.2088\n",
      "  400 loss:  -0.0019, free energy: -15.4902 ±  0.2203\n",
      "  500 loss:  -0.0045, free energy: -15.4960 ±  0.2018\n",
      "  600 loss:  -0.0004, free energy: -15.4897 ±  0.2234\n",
      "  700 loss:  -0.0051, free energy: -15.4962 ±  0.1989\n",
      "  800 loss:  -0.0036, free energy: -15.4960 ±  0.2006\n",
      "  900 loss:   0.0119, free energy: -15.4698 ±  0.2665\n",
      " 1000 loss:  -0.0064, free energy: -15.4926 ±  0.2137\n",
      " 1100 loss:   0.0005, free energy: -15.4887 ±  0.2241\n",
      " 1200 loss:  -0.0046, free energy: -15.4963 ±  0.1993\n",
      " 1300 loss:  -0.0034, free energy: -15.4964 ±  0.1989\n",
      " 1400 loss:   0.0045, free energy: -15.4602 ±  0.2740\n",
      " 1500 loss:   0.0059, free energy: -15.4759 ±  0.2633\n",
      " 1600 loss:  -0.0030, free energy: -15.4902 ±  0.2210\n",
      " 1700 loss:  -0.0051, free energy: -15.4939 ±  0.2097\n",
      " 1800 loss:  -0.0056, free energy: -15.4952 ±  0.2075\n",
      " 1900 loss:   0.0003, free energy: -15.4875 ±  0.2315\n",
      " 2000 loss:  -0.0021, free energy: -15.4924 ±  0.2158\n",
      "total time: 110.22s,  55.11ms per step.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 5000\n",
    "steps = 2000\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "tic = time.time()\n",
    "for k in range(steps):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} ±{:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "toc = time.time()\n",
    "print('total time: {:6.2f}s, {:6.2f}ms per step.'.format(toc-tic, (toc-tic)/steps*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short-range correlation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8074, 0.8101, 0.7988, 0.8088],\n",
      "        [0.8057, 0.7937, 0.7995, 0.7878],\n",
      "        [0.8053, 0.8152, 0.8027, 0.8149],\n",
      "        [0.8005, 0.7934, 0.7990, 0.7912]], device='cuda:0')\n",
      "tensor([[0.8197, 0.8057, 0.8142, 0.8069],\n",
      "        [0.8345, 0.8004, 0.8332, 0.8125],\n",
      "        [0.8219, 0.8033, 0.8164, 0.8084],\n",
      "        [0.8338, 0.8065, 0.8413, 0.8100]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = model.sample(100000);\n",
    "dims = tuple(range(-model.model.lattice.dimension,0))\n",
    "for shift in [(-1,0), (0,-1)]:\n",
    "    rolled = model.model.group.inv(x.roll(shift, dims))\n",
    "    coupled = model.model.group.mul(rolled, x)\n",
    "    corr = model.model.group(coupled, torch.tensor([1.,-1.]))\n",
    "    print(corr.mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Lattice (No Scale-Invariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the model and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = Model(H(0.440686793), TreeLattice(4, 2), SymmetricGroup(2))\n",
    "model = PixelGNN(model, hidden_features=[8, 8], radius=1.5, scale_invariance=False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.0052, free energy: -15.4751 ±  0.2636\n",
      "  200 loss:  -0.0032, free energy: -15.4756 ±  0.2536\n",
      "  300 loss:  -0.0050, free energy: -15.4774 ±  0.2510\n",
      "  400 loss:  -0.0051, free energy: -15.4774 ±  0.2537\n",
      "  500 loss:  -0.0042, free energy: -15.4785 ±  0.2533\n",
      "  600 loss:  -0.0054, free energy: -15.4787 ±  0.2524\n",
      "  700 loss:  -0.0044, free energy: -15.4775 ±  0.2570\n",
      "  800 loss:  -0.0058, free energy: -15.4769 ±  0.2528\n",
      "  900 loss:  -0.0057, free energy: -15.4791 ±  0.2511\n",
      " 1000 loss:  -0.0059, free energy: -15.4798 ±  0.2482\n",
      " 1100 loss:  -0.0062, free energy: -15.4797 ±  0.2501\n",
      " 1200 loss:  -0.0049, free energy: -15.4760 ±  0.2615\n",
      " 1300 loss:  -0.0059, free energy: -15.4786 ±  0.2559\n",
      " 1400 loss:  -0.0053, free energy: -15.4803 ±  0.2476\n",
      " 1500 loss:  -0.0033, free energy: -15.4772 ±  0.2592\n",
      " 1600 loss:  -0.0071, free energy: -15.4810 ±  0.2455\n",
      " 1700 loss:  -0.0058, free energy: -15.4815 ±  0.2459\n",
      " 1800 loss:  -0.0043, free energy: -15.4788 ±  0.2572\n",
      " 1900 loss:  -0.0032, free energy: -15.4807 ±  0.2525\n",
      " 2000 loss:  -0.0066, free energy: -15.4834 ±  0.2451\n",
      "total time: 111.97s,  55.99ms per step.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 5000\n",
    "steps = 2000\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "tic = time.time()\n",
    "for k in range(steps):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} ±{:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "toc = time.time()\n",
    "print('total time: {:6.2f}s, {:6.2f}ms per step.'.format(toc-tic, (toc-tic)/steps*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short-range correlation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8051, 0.7828, 0.7994, 0.7838],\n",
      "        [0.8053, 0.7586, 0.7926, 0.7517],\n",
      "        [0.7971, 0.7746, 0.7866, 0.7724],\n",
      "        [0.8098, 0.7715, 0.7993, 0.7634]], device='cuda:0')\n",
      "tensor([[0.7897, 0.7933, 0.7962, 0.7986],\n",
      "        [0.7898, 0.7839, 0.7955, 0.7904],\n",
      "        [0.7833, 0.7845, 0.7829, 0.7892],\n",
      "        [0.7812, 0.7774, 0.7895, 0.7831]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = model.sample(100000);\n",
    "dims = tuple(range(-model.model.lattice.dimension,0))\n",
    "for shift in [(-1,0), (0,-1)]:\n",
    "    rolled = model.model.group.inv(x.roll(shift, dims))\n",
    "    coupled = model.model.group.mul(rolled, x)\n",
    "    corr = model.model.group(coupled, torch.tensor([1.,-1.]))\n",
    "    print(corr.mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "- Although there are more parameters without scale invariance, the model is harder to converge (more easily trapped at local minimum of fully correlated configurations), and the performance is not improved.\n",
    "- The translation symmetry breaking still persists in the correlation function.\n",
    "\n",
    "**Possible Solution:** Consider symmetrizing the probability distribution. To restore the translation symmetry, one idea is to symmetrize the sample by random translations. This amounts to model the target probability $p(x)$ by a **mixtrue model**\n",
    "$$q_\\theta(x) = \\frac{1}{N}\\sum_a q_\\theta(T_a(x)),$$\n",
    "where $T_a$ denotes the translation operator that translates the configuration $x$ by $a$. $a$ is summed over the translation group of the lattice and $N$ is the order of the translation group.\n",
    "\n",
    "The loss function becomes\n",
    "$$\\begin{split}\\mathcal{L}&=\\sum_x \\Big(\\frac{1}{N}\\sum_a q_\\theta(T_a(x))\\Big)\\bigg(E(x)+\\ln \\Big(\\frac{1}{N}\\sum_b q_\\theta(T_b(x))\\Big)\\bigg)\\\\\n",
    "&=\\sum_x \\Big(\\frac{1}{N}\\sum_a q_\\theta(x)\\Big)\\bigg(E(T_{-a}(x))+\\ln \\Big(\\frac{1}{N}\\sum_b q_\\theta(T_{b-a}(x))\\Big)\\bigg)\\\\\n",
    "&=\\sum_x  q_\\theta(x)\\bigg(E(x)+\\ln \\Big(\\frac{1}{N}\\sum_b q_\\theta(T_{b}(x))\\Big)\\bigg)\n",
    "\\end{split}$$\n",
    "Here we have used the fact that the summation of configuration $\\sum_x$, the summation of translation group $\\sum_b$ and the energy function $E(x)$ are all translationally invariant. Therefore, we only need to replace the log probability by its symmetrized version, which can be approximate by the log-mean-exp of the log probability over finite number of random translations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixtrue Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Space Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Space group operation of a point $x\\in \\mathbb{Z}_n^d$ includes:\n",
    "- translation $x\\to x+a$ for $a\\in \\mathbb{Z}_n^d$,\n",
    "- inversion $x\\to (-)^s\\odot x$ for $s\\in \\mathbb{Z}_2^d$,\n",
    "- permutation of coordinates $(x_1,x_2,\\cdots)\\to(x_{\\pi_1}, x_{\\pi_2},\\cdots)$ for $\\pi\\in S_d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`randperm(sample_size)` method samples random space group transformation (as site permutation) of the lattice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 10,  6,  2, 15, 11,  7,  3, 12,  8,  4,  0, 13,  9,  5,  1],\n",
       "        [ 1, 13,  9,  5,  0, 12,  8,  4,  3, 15, 11,  7,  2, 14, 10,  6],\n",
       "        [12, 13, 14, 15,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lattice(4,2).randperm(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%r\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = Model(H(0.440686793), TreeLattice(4, 2), SymmetricGroup(2))\n",
    "model = PixelGNN(model, hidden_features=[8, 8], radius=1.5, mixtures=4).to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 0, 1, 0],\n",
       "          [0, 0, 0, 1],\n",
       "          [1, 0, 0, 0],\n",
       "          [1, 0, 1, 0]],\n",
       "\n",
       "         [[1, 0, 0, 0],\n",
       "          [1, 0, 1, 0],\n",
       "          [1, 0, 1, 0],\n",
       "          [0, 1, 0, 0]]],\n",
       "\n",
       "\n",
       "        [[[1, 1, 0, 0],\n",
       "          [0, 1, 0, 1],\n",
       "          [1, 1, 1, 0],\n",
       "          [0, 0, 1, 1]],\n",
       "\n",
       "         [[1, 0, 1, 1],\n",
       "          [0, 1, 1, 0],\n",
       "          [1, 0, 0, 1],\n",
       "          [0, 1, 0, 1]]],\n",
       "\n",
       "\n",
       "        [[[1, 0, 1, 0],\n",
       "          [0, 1, 0, 1],\n",
       "          [0, 1, 0, 1],\n",
       "          [0, 1, 0, 1]],\n",
       "\n",
       "         [[0, 1, 0, 1],\n",
       "          [0, 1, 0, 1],\n",
       "          [1, 0, 1, 0],\n",
       "          [0, 1, 0, 1]]]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.sample(3)\n",
    "xs = model.randmix(x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin statistics is a technique to estimate the expectation of a nonlinear map of random variables. In our problem, we need to evaluate the log probability of the mixture model $\\ln(\\frac{1}{N}\\sum_{b}q_\\theta(T_b(x)))$ with finite number of samples. Suppose $\\bar{q}_\\theta$ be the expectation of $q_\\theta$ in the large-$N$ limit, we expect\n",
    "$$\\ln\\big(\\frac{1}{N}\\sum q_\\theta\\big)=\\ln\\big(\\bar{q}_\\theta + \\frac{1}{N}\\sum \\delta q_\\theta\\big)=\\ln \\bar{q}_\\theta - \\frac{1}{2N}\\frac{\\text{var}(\\delta q_\\theta)}{\\bar{q}_\\theta^2}+\\mathcal{O}(N^{-2})$$\n",
    "Therefore we should estimate the log of mixture probability by\n",
    "$$\\ln \\bar{q}_\\theta \\simeq \\ln\\big(\\frac{1}{N}\\sum q_\\theta\\big)+ \\frac{1}{2N}\\frac{\\text{var}(q_\\theta)}{\\bar{q}_\\theta^2}.$$\n",
    "In evaluating the subleading term, $q_\\theta$ can be renormalized by an overall factor to avoid over/under flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.6945, -9.2867, -5.4256], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.2184, -10.4397,  -7.2398], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_mixed_prob(x, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%r\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = Model(H(0.440686793), FlatLattice(4, 2), SymmetricGroup(2))\n",
    "model = PixelGNN(model, hidden_features=[8, 8], radius=2.01).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.3220, free energy: -14.6379 ±  0.5976\n",
      "  200 loss:   0.1130, free energy: -15.0297 ±  0.4113\n",
      "  300 loss:   0.0331, free energy: -15.2847 ±  0.4678\n",
      "  400 loss:  -0.0740, free energy: -15.4785 ±  0.2889\n",
      "  500 loss:  -0.0492, free energy: -15.4928 ±  0.2397\n",
      "  600 loss:  -0.0434, free energy: -15.5005 ±  0.2060\n",
      "  700 loss:  -0.0256, free energy: -15.4858 ±  0.2451\n",
      "  800 loss:  -0.0386, free energy: -15.5050 ±  0.1848\n",
      "  900 loss:  -0.0347, free energy: -15.5062 ±  0.1775\n",
      " 1000 loss:  -0.0326, free energy: -15.5072 ±  0.1700\n",
      " 1100 loss:  -0.0259, free energy: -15.5038 ±  0.1844\n",
      " 1200 loss:  -0.0233, free energy: -15.5037 ±  0.1858\n",
      " 1300 loss:  -0.0278, free energy: -15.5091 ±  0.1604\n",
      " 1400 loss:  -0.0273, free energy: -15.5092 ±  0.1580\n",
      " 1500 loss:  -0.0157, free energy: -15.5002 ±  0.1942\n",
      " 1600 loss:  -0.0268, free energy: -15.5100 ±  0.1551\n",
      " 1700 loss:  -0.0247, free energy: -15.5104 ±  0.1505\n",
      " 1800 loss:  -0.0250, free energy: -15.5096 ±  0.1553\n",
      " 1900 loss:  -0.0229, free energy: -15.5103 ±  0.1528\n",
      " 2000 loss:  -0.0232, free energy: -15.5098 ±  0.1539\n",
      "total time: 147.50s,  73.75ms per step.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 5000\n",
    "steps = 2000\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "tic = time.time()\n",
    "for k in range(steps):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} ±{:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "toc = time.time()\n",
    "print('total time: {:6.2f}s, {:6.2f}ms per step.'.format(toc-tic, (toc-tic)/steps*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%r\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = Model(H(0.440686793), FlatLattice(4, 2), SymmetricGroup(2))\n",
    "model = PixelGNN(model, hidden_features=[8, 8], radius=2.01).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:   0.9273, free energy: -14.4217 ±  1.5607\n",
      "  200 loss:  -0.3956, free energy: -14.9241 ±  0.9625\n",
      "  300 loss:  -0.7220, free energy: -15.3860 ±  0.7543\n",
      "  400 loss:  -0.2778, free energy: -15.5271 ±  0.3313\n",
      "  500 loss:  -0.1579, free energy: -15.5233 ±  0.2587\n",
      "  600 loss:  -0.1072, free energy: -15.5220 ±  0.2335\n",
      "  700 loss:  -0.0918, free energy: -15.5189 ±  0.2196\n",
      "  800 loss:  -0.0892, free energy: -15.5210 ±  0.2138\n",
      "  900 loss:  -0.0564, free energy: -15.5204 ±  0.2210\n",
      " 1000 loss:  -0.0489, free energy: -15.5174 ±  0.2940\n",
      " 1100 loss:  -0.0707, free energy: -15.5202 ±  0.1886\n",
      " 1200 loss:  -0.0562, free energy: -15.5218 ±  0.1809\n",
      " 1300 loss:  -0.0490, free energy: -15.5217 ±  0.1818\n",
      " 1400 loss:  -0.0445, free energy: -15.5212 ±  0.1716\n",
      " 1500 loss:  -0.0414, free energy: -15.5217 ±  0.1743\n",
      " 1600 loss:  -0.0356, free energy: -15.5208 ±  0.1903\n",
      " 1700 loss:  -0.0388, free energy: -15.5191 ±  0.1782\n",
      " 1800 loss:   0.0074, free energy: -15.5172 ±  0.3311\n",
      " 1900 loss:  -0.0246, free energy: -15.5267 ±  0.4125\n",
      " 2000 loss:  -0.0561, free energy: -15.5215 ±  0.1784\n",
      "total time: 162.86s,  81.43ms per step.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 5000\n",
    "steps = 2000\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "tic = time.time()\n",
    "for k in range(steps):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, mixtures=2, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} ±{:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "toc = time.time()\n",
    "print('total time: {:6.2f}s, {:6.2f}ms per step.'.format(toc-tic, (toc-tic)/steps*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 mixtures, scale-invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%r\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = Model(H(0.440686793), TreeLattice(4, 2), SymmetricGroup(2))\n",
    "model = PixelGNN(model, hidden_features=[8, 8], radius=1.5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.3460, free energy: -15.1937 ±  1.5339\n",
      "  200 loss:  -0.1629, free energy: -15.5608 ±  0.9051\n",
      "  300 loss:   0.0047, free energy: -15.5330 ±  0.7099\n",
      "  400 loss:  -0.0880, free energy: -15.5308 ±  0.6101\n",
      "  500 loss:  -0.0123, free energy: -15.5319 ±  0.5071\n",
      "  600 loss:  -0.0285, free energy: -15.5335 ±  0.4480\n",
      "  700 loss:  -0.0214, free energy: -15.5268 ±  0.3983\n",
      "  800 loss:  -0.0184, free energy: -15.5257 ±  0.3715\n",
      "  900 loss:  -0.0224, free energy: -15.5262 ±  0.3481\n",
      " 1000 loss:  -0.0190, free energy: -15.5307 ±  0.3410\n",
      " 1100 loss:  -0.0135, free energy: -15.5254 ±  0.3330\n",
      " 1200 loss:  -0.0235, free energy: -15.5277 ±  0.3440\n",
      " 1300 loss:  -0.0191, free energy: -15.5251 ±  0.3231\n",
      " 1400 loss:  -0.0134, free energy: -15.5259 ±  0.2944\n",
      " 1500 loss:  -0.0159, free energy: -15.5281 ±  0.2985\n",
      " 1600 loss:  -0.0122, free energy: -15.5252 ±  0.2914\n",
      " 1700 loss:  -0.0214, free energy: -15.5244 ±  0.2825\n",
      " 1800 loss:  -0.0155, free energy: -15.5202 ±  0.3095\n",
      " 1900 loss:  -0.0100, free energy: -15.5234 ±  0.2789\n",
      " 2000 loss:  -0.0149, free energy: -15.5242 ±  0.2815\n",
      "total time: 151.60s,  75.80ms per step.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 5000\n",
    "steps = 2000\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "tic = time.time()\n",
    "for k in range(steps):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, mixtures=2, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} ±{:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "toc = time.time()\n",
    "print('total time: {:6.2f}s, {:6.2f}ms per step.'.format(toc-tic, (toc-tic)/steps*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 mixtures, scale-invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%r\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = Model(H(0.440686793), TreeLattice(4, 2), SymmetricGroup(2))\n",
    "model = PixelGNN(model, hidden_features=[8, 8], radius=1.5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.3825, free energy: -15.3044 ±  1.2170\n",
      "  200 loss:  -0.0540, free energy: -15.5257 ±  0.4823\n",
      "  300 loss:   0.0003, free energy: -15.5078 ±  0.3442\n",
      "  400 loss:   0.0071, free energy: -15.5129 ±  0.3115\n",
      "  500 loss:  -0.0018, free energy: -15.5215 ±  0.2993\n",
      "  600 loss:  -0.0081, free energy: -15.5197 ±  0.2747\n",
      "  700 loss:  -0.0010, free energy: -15.5167 ±  0.2644\n",
      "  800 loss:  -0.0068, free energy: -15.5206 ±  0.2535\n",
      "  900 loss:  -0.0042, free energy: -15.5233 ±  0.2364\n",
      " 1000 loss:  -0.0050, free energy: -15.5221 ±  0.2313\n",
      " 1100 loss:  -0.0087, free energy: -15.5224 ±  0.2202\n",
      " 1200 loss:  -0.0089, free energy: -15.5189 ±  0.2153\n",
      " 1300 loss:   0.0002, free energy: -15.5210 ±  0.2350\n",
      " 1400 loss:  -0.0051, free energy: -15.5231 ±  0.2060\n",
      " 1500 loss:  -0.0008, free energy: -15.5208 ±  0.2086\n",
      " 1600 loss:  -0.0048, free energy: -15.5231 ±  0.2086\n",
      " 1700 loss:  -0.0049, free energy: -15.5186 ±  0.1963\n",
      " 1800 loss:  -0.0020, free energy: -15.5195 ±  0.1952\n",
      " 1900 loss:  -0.0046, free energy: -15.5209 ±  0.1963\n",
      " 2000 loss:  -0.0016, free energy: -15.5199 ±  0.1993\n",
      "total time: 209.84s, 104.92ms per step.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 5000\n",
    "steps = 2000\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "tic = time.time()\n",
    "for k in range(steps):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, mixtures=4, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} ±{:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "toc = time.time()\n",
    "print('total time: {:6.2f}s, {:6.2f}ms per step.'.format(toc-tic, (toc-tic)/steps*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 mixtures, scale-invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%r\n",
    "H = lambda J: -J*(TwoBody([1,0],[1,-1]) + TwoBody([0,1],[1,-1]))\n",
    "model = Model(H(0.440686793), TreeLattice(4, 2), SymmetricGroup(2))\n",
    "model = PixelGNN(model, hidden_features=[8, 8], radius=1.5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 loss:  -0.8319, free energy: -15.0163 ±  1.0294\n",
      "  200 loss:  -0.0243, free energy: -15.5077 ±  0.3929\n",
      "  300 loss:  -0.0091, free energy: -15.5093 ±  0.3110\n",
      "  400 loss:   0.0055, free energy: -15.5146 ±  0.2755\n",
      "  500 loss:   0.0035, free energy: -15.5175 ±  0.2530\n",
      "  600 loss:   0.0048, free energy: -15.5162 ±  0.2436\n",
      "  700 loss:   0.0027, free energy: -15.5113 ±  0.2447\n",
      "  800 loss:   0.0025, free energy: -15.5185 ±  0.1948\n",
      "  900 loss:   0.0036, free energy: -15.5152 ±  0.1894\n",
      " 1000 loss:   0.0047, free energy: -15.5190 ±  0.1747\n",
      " 1100 loss:   0.0023, free energy: -15.5216 ±  0.1672\n",
      " 1200 loss:   0.0032, free energy: -15.5208 ±  0.1606\n",
      " 1300 loss:   0.0079, free energy: -15.5199 ±  0.1554\n",
      " 1400 loss:   0.0048, free energy: -15.5220 ±  0.1560\n",
      " 1500 loss:   0.0019, free energy: -15.5219 ±  0.1416\n",
      " 1600 loss:   0.0040, free energy: -15.5203 ±  0.1449\n",
      " 1700 loss:   0.0025, free energy: -15.5184 ±  0.1480\n",
      " 1800 loss:   0.0050, free energy: -15.5211 ±  0.1387\n",
      " 1900 loss:   0.0041, free energy: -15.5184 ±  0.1442\n",
      " 2000 loss:   0.0065, free energy: -15.5201 ±  0.1400\n",
      "total time: 620.65s, 310.33ms per step.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 5000\n",
    "steps = 2000\n",
    "echo = 100\n",
    "cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "tic = time.time()\n",
    "for k in range(steps):\n",
    "    loss, meanfree, stdfree = model.loss(batch_size, mixtures=16, return_statistics=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cum_loss += loss.item()\n",
    "    cum_meanfree += meanfree\n",
    "    cum_stdfree += stdfree\n",
    "    if (k+1)%echo == 0:\n",
    "        print('{:5} loss: {:8.4f}, free energy: {:8.4f} ±{:8.4f}'.format(k+1, cum_loss/echo, cum_meanfree/echo, cum_stdfree/echo))\n",
    "        cum_loss, cum_meanfree,cum_stdfree = 0., 0., 0.\n",
    "toc = time.time()\n",
    "print('total time: {:6.2f}s, {:6.2f}ms per step.'.format(toc-tic, (toc-tic)/steps*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
